{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Initially, we will be looking at the identification of **named entities**, i.e. identifying references to entities in a text. This is also sometimes referred to as **entity extraction** or **named entity recognition**. A reference to a named entity in a text is referred to as an **entity mention**.\n",
    "\n",
    "#### Named Entity Recognition\n",
    "\n",
    "Named-entity recognition (NER) (also known as entity identification, entity chunking and entity extraction) is a subtask of information extraction that seeks to locate and classify named entities in text into pre-defined categories such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages, etc.\n",
    "\n",
    "Most research on NER systems has been structured as taking an unannotated block of text, such as this one:\n",
    "\n",
    "Jim bought 300 shares of Acme Corp. in 2006.\n",
    "\n",
    "And producing an annotated block of text that highlights the names of entities:\n",
    "\n",
    "[Jim]Person bought 300 shares of [Acme Corp.]Organization in [2006]Time.\n",
    "\n",
    "In this example, a person name consisting of one token, a two-token company name and a temporal expression have been detected and classified.\n",
    "\n",
    "State-of-the-art NER systems for English produce near-human performance. For example, the best system entering MUC-7 scored 93.39% of F-measure while human annotators scored 97.60% and 96.95%\n",
    "\n",
    "#### Problem Statement\n",
    "\n",
    "In the expression named entity, the word named restricts the task to those entities for which one or many strings, such as words or phrases, stands (fairly) consistently for some referent. This is closely related to rigid designators, as defined by Kripki, although in practice NER deals with many names and referents that are not philosophically \"rigid\". For instance, the automotive company created by Henry Ford in 1903 can be referred to as Ford or Ford Motor Company, although \"Ford\" can refer to many other entities as well. Rigid designators include proper names as well as terms for certain biological species and substances,[5] but exclude pronouns (such as \"it\"; see coreference resolution), descriptions that pick out a referent by its properties (see also De dicto and de re), and names for kinds of things as opposed to individuals (for example \"Bank\").\n",
    "\n",
    "Full named-entity recognition is often broken down, conceptually and possibly also in implementations, as two distinct problems: detection of names, and classification of the names by the type of entity they refer to (e.g. person, organization, location and other). The first phase is typically simplified to a segmentation problem: names are defined to be contiguous spans of tokens, with no nesting, so that \"Bank of America\" is a single name, disregarding the fact that inside this name, the substring \"America\" is itself a name. This segmentation problem is formally similar to chunking. The second phase requires choosing an ontology by which to organize categories of things.\n",
    "\n",
    "#### Evaluation\n",
    "\n",
    "To evaluate the quality of a NER system's output, several measures have been defined. While accuracy on the token level is one possibility, it suffers from two problems: the vast majority of tokens in real-world text are not part of entity names as usually defined, so the baseline accuracy (always predict \"not an entity\") is extravagantly high, typically >90%; and mispredicting the full span of an entity name is not properly penalized (finding only a person's first name when their last name follows is scored as Â½ accuracy).\n",
    "\n",
    "In academic conferences such as CoNLL, a variant of the F1 score has been defined as follows:\n",
    "\n",
    "Precision is the number of predicted entity name spans that line up exactly with spans in the gold standard evaluation data. I.e. when [Person Hans] [Person Blick] is predicted but [Person Hans Blick] was required, precision for the predicted name is zero. Precision is then averaged over all predicted entity names.\n",
    "Recall is similarly the number of names in the gold standard that appear at exactly the same location in the predictions.\n",
    "F1 score is the harmonic mean of these two.\n",
    "It follows from the above definition that any prediction that misses a single token, includes a spurious token, or has the wrong class, is a hard error and does not contribute to either precision or recall.\n",
    "\n",
    "Evaluation models based on a token-by-token matching have been proposed. Such models are able to handle also partially overlapping matches, yet fully rewarding only exact matches. They allow a finer grained evaluation and comparison of extraction systems, taking into account also the degree of mismatch in non-exact predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries to be imported to accomplish the task of identifying entities, predicting gender and portrayal of characters in a novel using SpaCy library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sussex NLTK root directory is C:\\Users\\cmm\\Desktop\\NLP\\resources\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r'\\\\ad.susx.ac.uk\\ITS\\TeachingResources\\Departments\\Informatics\\LanguageEngineering\\resources')\n",
    "#sys.path.append(r'/Users/davidw/Documents/teach/NLE/resources')\n",
    "import os\n",
    "os.chdir('C://Users//cmm//Desktop//NLP//resources')\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict,Counter\n",
    "from itertools import zip_longest\n",
    "from IPython.display import display\n",
    "from random import seed\n",
    "import random\n",
    "import math\n",
    "from pylab import rcParams\n",
    "from operator import itemgetter, attrgetter, methodcaller\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import seaborn as sns\n",
    "import csv\n",
    "from operator import itemgetter, attrgetter, methodcaller\n",
    "import matplotlib.pylab as pylab\n",
    "%matplotlib inline\n",
    "params = {'legend.fontsize': 'large',\n",
    "          'figure.figsize': (15, 5),\n",
    "         'axes.labelsize': 'large',\n",
    "         'axes.titlesize':'large',\n",
    "         'xtick.labelsize':'large',\n",
    "         'ytick.labelsize':'large'}\n",
    "pylab.rcParams.update(params)\n",
    "get_ipython().magic('matplotlib inline')\n",
    "import spacy\n",
    "from sussex_nltk.corpus_readers import AmazonReviewCorpusReader\n",
    "from nltk.corpus import gutenberg\n",
    "nlp = spacy.load('en')\n",
    "from GutenbergCorpus import GutenbergCorpusReader as gcr\n",
    "reader = gcr.GutenbergCorpusReader()                         ## Sussex constructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code imports data from gutenberg corpus, Jane Austin's Emma is the novel used. The code parses the novel and 100 sample sentences are selected, these 100 sentences are going to be used for extracting entities from a sentence.\n",
    "\n",
    "#### In information extraction, a named entity is a real-world object, such as persons, locations, organizations, products, etc., that can be denoted with a proper name. It can be abstract or have a physical existence. Examples of named entities include Barack Obama,Manchester, Volkswagen Golf, or anything else that can be named. Named entities can simply be viewed as entity instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "emma = gutenberg.raw('austen-emma.txt')\n",
    "parsed_emma = nlp(emma)\n",
    "sense = gutenberg.raw('austen-sense.txt')\n",
    "parsed_sense=nlp(sense)\n",
    "moby = gutenberg.raw('melville-moby_dick.txt')\n",
    "parsed_moby=nlp(moby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A very serious sort, I assure you;\" still smiling.  \n",
      "\n",
      "\"Who is that gentleman on horseback?\" said she, as they proceeded-- speaking more to assist Mr. Weston in keeping his secret, than with any other view.  \n",
      "\n",
      "I think I can give you a proof that it must be so.  \n",
      "\n",
      "I hope she is right.--In one respect, my good fortune is undoubted, that of being able to subscribe myself, Your obliged and affectionate Son, F. C. WESTON CHURCHILL. CHAPTER XV  \n",
      "\n",
      "\"Something that would do!\" repeated Mrs. Elton. \"Aye, _that_ may suit your humble ideas of yourself;--I know what a modest creature you are; but it will not satisfy your friends to have you taking up with any thing that may offer, any inferior, commonplace situation, in a family not moving in a certain circle, or able to command the elegancies of life.\"  \n",
      "\n",
      "She has been so kind as to promise it.  \n",
      "\n",
      "\"And if the Dixons should absolutely deny all knowledge of it we must conclude it to come from the Campbells.\"  \n",
      "\n",
      "\"Oh no! \n",
      "\n",
      "If she has it now, you have given it.  \n",
      "\n",
      "[Emma by Jane Austen 1816] VOLUME I CHAPTER \n",
      "\n",
      "William did not seem to mind it himself, he was so pleased to think his master had sold so many; for William, you know, thinks more of his master's profit than any thing; but Mrs. Hodges, he said, was quite displeased at their being all sent away.  \n",
      "\n",
      "\" They were permitted to go alone; and with a cordial nod from one, and a graceful bow from the other, the two gentlemen took leave.  \n",
      "\n",
      "That, I thought, in a man of known musical talent, was some proof.\"  \n",
      "\n",
      "\"I had a few lines on parish business from Mr. Weston this morning, and at the end of them he gave me a brief account of what had happened.\"  \n",
      "\n",
      "In a country life I conceive it to be a sort of necessary; for, let a woman have ever so many resources, it is not possible for her to be always shut up at home;--and very long walks, you know--in summer there is dust, and in winter there is dirt.\"  \n",
      "\n",
      "Why had not Miss Woodhouse revived the former good old days of the room?--She who could do any thing in Highbury!  \n",
      "\n",
      "What do you deserve?\"  \n",
      "\n",
      "Emma was sure he had not forgiven her; he looked unlike himself.  \n",
      "\n",
      "He listened in perfect silence.  \n",
      "\n",
      "\"My father and Mrs. Weston are at the Crown at this moment,\" said Frank Churchill, \"examining the capabilities of the house.  \n",
      "\n",
      "\" \"I do not admire it,\" said Mr. Knightley.  \n",
      "\n",
      "If _we_ exert ourselves, I think we shall not be long in want of allies.  \n",
      "\n",
      "I think you must know Hartfield enough to comprehend that.\"  \n",
      "\n",
      "I shall never forget it.  \n",
      "\n",
      "\"No, I have not; I know nothing; pray tell me.\"  \n",
      "\n",
      "\"To be sure we do,\" cried his father; \"Mrs. Bates--we passed her house--  \n",
      "\n",
      "Her voice was not unsteady; but her mind was in all the perturbation that such a development of self, such a burst of threatening evil, such a confusion of sudden and perplexing emotions, must create.--  \n",
      "\n",
      "A reasonable visit paid, Mr. Weston began to move.--\"He must be going.  \n",
      "\n",
      "True affection only could have prompted it.\"  \n",
      "\n",
      "CHAPTER XVI  \n",
      "\n",
      "How very odd!  \n",
      "\n",
      "Now, if your friends have any gratitude, they will say something pretty loud about you and me in return; but I cannot stay to hear it.\"  \n",
      "\n",
      "\"Well! that is quite surprising, for we have had a vast deal of rain here.  \n",
      "\n",
      "` \n",
      "\n",
      "My blindness to what was going on, led me to act by them in a way that I must always be ashamed of, and I was very foolishly tempted to say and do many things which may well lay me open to unpleasant conjectures, but I have no other reason to regret that I was not in the secret earlier.\"  \n",
      "\n",
      "Mr. Perry did say so.  \n",
      "\n",
      "I had got my bonnet and spencer on, just ready to come out \n",
      "\n",
      "A Miss Hawkins of Bath.  \n",
      "\n",
      "Emma found it really time to be at home; the visit had already lasted long; and on examining watches, so much of the morning was perceived to be gone, that Mrs. Weston and her companion taking leave also, could allow themselves only to walk with the two young ladies to Hartfield gates, before they set off for Randalls.  \n",
      "\n",
      "\"But you, who are so extremely fond of it--there can be no danger, surely?\"  \n",
      "\n",
      "Perry tells me that Mr. Cole never touches malt liquor.  \n",
      "\n",
      "Either in the morning or evening of every day, excepting one, have we seen either Mr. Weston or Mrs. Weston, and generally both, either at Randalls or here--and as you may suppose, Isabella, most frequently here.  \n",
      "\n",
      "Give me the book, I will write it down, and then there can be no possible reflection on you.\"  \n",
      "\n",
      "She read it to him, just as he liked to have any thing read, slowly and distinctly, and two or three times over, with explanations of every part as she proceeded--and he was very much pleased, and, as she had foreseen, especially struck with the complimentary conclusion. \" \n",
      "\n",
      "So sudden!--You may guess, dear Miss Woodhouse, what a flurry it has thrown me in!  \n",
      "\n",
      "I am sure she will be pleased with the children.  \n",
      "\n",
      "\"That may be--but not by sketches in Swisserland.  \n",
      "\n",
      "least you admire her except her complexion.\"  \n",
      "\n",
      "But you will do every thing right.  \n",
      "\n",
      "Matrimony, as the origin of change, was always disagreeable; and he was by no means yet reconciled to his own daughter's marrying, nor could ever speak of her but with compassion, though it had been entirely a match of affection, when he was now obliged to part with Miss Taylor too; and from his habits of gentle selfishness, and of being never able to suppose that other people could feel differently from himself, he was very much disposed to think Miss Taylor had done as sad a thing for herself as for them, and would have been a great deal happier if she had spent all the rest of her life at Hartfield.  \n",
      "\n",
      "But in time they will.  \n",
      "\n",
      "There is my sister; and really quite her own little elegant figure!--and the face not unlike.  \n",
      "\n",
      "Mrs. Goddard, and the teachers, and the girls and the affairs of the school in general, formed naturally a great part of the conversation--and but for her acquaintance with the Martins of Abbey-Mill Farm, it must have been the whole.  \n",
      "\n",
      "but otherwise I could not have imagined it.  \n",
      "\n",
      "\" \n",
      "\n",
      "Emma made as slight a reply as she could; but it was fully sufficient for Mrs. Elton, who only wanted to be talking herself.  \n",
      "\n",
      "Poor girl!  \n",
      "\n",
      "I saw a vast deal of that in the neighbourhood round Maple Grove.  \n",
      "\n",
      "Always the first person to be thought of!  \n",
      "\n",
      "If meant to be immediately mixed with the others, and buried from sight, she should have looked on the table instead of looking just across, for it was not mixed; and Harriet, eager after every fresh word, and finding out none, directly took it up, and fell to work.  \n",
      "\n",
      "And such a noble fire!--I am quite roasted.  \n",
      "\n",
      "Alas! \n",
      "\n",
      "\"Ever hear her!\" repeated Emma. \" \n",
      "\n",
      "It soon appeared that London was not the place for her.  \n",
      "\n",
      "Mr. Knightley soon saw that he had lost his moment, and that not another syllable of communication could rest with him.  \n",
      "\n",
      "You provide for the family, you know, (with a smile at his father). \n",
      "\n",
      "He had been too much expected by the best judges, for surprize-- but there was great joy.  \n",
      "\n",
      "Well! \n",
      "\n",
      "\"Yes, that of course.\"  \n",
      "\n",
      "Mrs. Weston and Emma were sitting together on a sofa.  \n",
      "\n",
      "Chuse your own degree of crossness.  \n",
      "\n",
      "There is to be no form or parade--a sort of gipsy party.  \n",
      "\n",
      "Now, as her objection was nothing but her very great dislike of Mrs. Elton, of which Mr. Weston must already be perfectly aware, it was not worth bringing forward again:--it could not be done without a reproof to him, which would be giving pain to his wife; and she found herself therefore obliged to consent to an arrangement which she would have done a great deal to avoid; an arrangement which would probably expose her even to the degradation of being said to be of Mrs. Elton's party!  \n",
      "\n",
      "\"Your feelings are singular.  \n",
      "\n",
      "\"This is very true,\" said she, \"at least as far as relates to me, which was all that was meant--and it is very shameful.--Of the same age-- and always knowing her--I ought to have been more her friend.--  \n",
      "\n",
      "\" \n",
      "\n",
      "It would be a great disappointment to Mr. John Knightley; consequently to Isabella.  \n",
      "\n",
      "Oh! \n",
      "\n",
      "It was folly to be disturbed by it.  \n",
      "\n",
      "Harriet would have been a better match.  \n",
      "\n",
      "Another view of man, my second brings,  \n",
      "\n",
      "It did, however.--Her father was quite taken up with the surprize of so sudden a journey, and his fears that Mr. Elton might never get safely to the end of it, and saw nothing extraordinary in his language.  \n",
      "\n",
      "No, if he had believed me at all to share his feelings, he would not have been so wretched.  \n",
      "\n",
      "\"Oh! \n",
      "\n",
      "If I could but see her again!--But I must not propose it yet.  \n",
      "\n",
      "After such behaviour, as I have witnessed during the last month, to Miss Smith--such attentions as I have been in the daily habit of observing--to be addressing me in this manner--this is an unsteadiness of character, indeed, which I had not supposed possible!  \n",
      "\n",
      "I thought it very well done of him indeed.  \n",
      "\n",
      "\" \"Handsome!  \n",
      "\n",
      "\"Oh! \n",
      "\n",
      "\"It is a sort of thing,\" cried Mrs. Elton emphatically, \"which _I_ should not have thought myself privileged to inquire into.  \n",
      "\n",
      "Kitty, a fair but frozen maid.  \n",
      "\n",
      "You may guess how readily he came into my wishes; and having his approbation, I made my way directly to Miss Bates, to assure her that the carriage would be at her service before it took us home; for I thought it would be making her comfortable at once.  \n",
      "\n",
      "The conversation was here interrupted.  \n",
      "\n",
      "\"Never, madam,\" cried he, affronted in his turn: \"never, I assure you.  \n",
      "\n",
      "Oh! no--far from it--certainly plain.  \n",
      "\n",
      "But perhaps he may never have heard of there being such a creature in the world.\"  \n",
      "\n",
      "This was very kind of you to be persuaded to come.  \n",
      "\n",
      "CHAPTER IV  \n",
      "\n",
      "If _she_ had so misinterpreted his feelings, she had little right to wonder that _he_, with self-interest to blind him, should have mistaken hers.  \n",
      "\n",
      "He was not hungry; it would only make him hotter.\"  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "seed(181520)\n",
    "sample_size = 100\n",
    "my_sample = random.sample(list(parsed_emma.sents),sample_size) # select a random sample of sentences\n",
    "sample=[]\n",
    "for sent in my_sample:\n",
    "    sent = re.sub(\"\\s+\",\" \",sent.text) # clean up the whitespace\n",
    "    print(sent,\"\\n\")\n",
    "    sample.append(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Named entities can take the following form:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " {[u'CARDINAL', u'DATE', u'EVENT', u'FAC', u'GPE', u'LANGUAGE', u'LAW', u'LOC', u'MONEY', u'NORP', u'ORDINAL', u'ORG', u'PERCENT', u'PERSON', u'PRODUCT', u'QUANTITY', u'TIME', u'WORK_OF_ART'], u'0': [u''], u'3': [u'CARDINAL', u'DATE', u'EVENT', u'FAC', u'GPE', u'LANGUAGE', u'LAW', u'LOC', u'MONEY', u'NORP', u'ORDINAL', u'ORG', u'PERCENT', u'PERSON', u'PRODUCT', u'QUANTITY', u'TIME', u'WORK_OF_ART'], u'2': [u'CARDINAL', u'DATE', u'EVENT', u'FAC', u'GPE', u'LANGUAGE', u'LAW', u'LOC', u'MONEY', u'NORP', u'ORDINAL', u'ORG', u'PERCENT', u'PERSON', u'PRODUCT', u'QUANTITY', u'TIME', u'WORK_OF_ART'], u'5': [u''], u'4': [u'CARDINAL', u'DATE', u'EVENT', u'FAC', u'GPE', u'LANGUAGE', u'LAW', u'LOC', u'MONEY', u'NORP', u'ORDINAL', u'ORG', u'PERCENT', u'PERSON', u'PRODUCT', u'QUANTITY', u'TIME', u'WORK_OF_ART']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 100 sentences are iterated over and the entities are extracted from each sentence with tagged entities. Now these are classified according to entity type and misclassified examples are aggregated manually. A Dataframe is output containing Entities and their types in sample set of sentences. Upon running the code it was found that person class has maximum entries as expected because of characters in a novel. Also mentions of 8 other entity types are recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Entity_type</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Weston</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>\"Who is that gentleman on horseback?\" said she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Son</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>I hope she is right.--In one respect, my good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F. C. WESTON CHURCHILL.</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>I hope she is right.--In one respect, my good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elton</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>\"Something that would do!\" repeated Mrs. Elton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dixons</td>\n",
       "      <td>ORG</td>\n",
       "      <td>\"And if the Dixons should absolutely deny all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Emma</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>[Emma by Jane Austen 1816] VOLUME I CHAPTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>[Emma by Jane Austen 1816] VOLUME I CHAPTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1816</td>\n",
       "      <td>DATE</td>\n",
       "      <td>[Emma by Jane Austen 1816] VOLUME I CHAPTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>William</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>William did not seem to mind it himself, he wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hodges</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>William did not seem to mind it himself, he wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>one</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>\" They were permitted to go alone; and with a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>two</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>\" They were permitted to go alone; and with a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>this morning</td>\n",
       "      <td>TIME</td>\n",
       "      <td>\"I had a few lines on parish business from Mr....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Woodhouse</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>Why had not Miss Woodhouse revived the former ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Highbury</td>\n",
       "      <td>GPE</td>\n",
       "      <td>Why had not Miss Woodhouse revived the former ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Crown</td>\n",
       "      <td>ORG</td>\n",
       "      <td>\"My father and Mrs. Weston are at the Crown at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Frank Churchill</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>\"My father and Mrs. Weston are at the Crown at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Knightley</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>\" \"I do not admire it,\" said Mr. Knightley.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Hartfield</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>I think you must know Hartfield enough to comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bates</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>\"To be sure we do,\" cried his father; \"Mrs. Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Perry</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>Mr. Perry did say so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Hawkins</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>A Miss Hawkins of Bath.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Randalls</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Emma found it really time to be at home; the v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Cole</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>Perry tells me that Mr. Cole never touches mal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>morning</td>\n",
       "      <td>TIME</td>\n",
       "      <td>Either in the morning or evening of every day,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>evening</td>\n",
       "      <td>TIME</td>\n",
       "      <td>Either in the morning or evening of every day,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Isabella</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>Either in the morning or evening of every day,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>two or three times</td>\n",
       "      <td>DATE</td>\n",
       "      <td>She read it to him, just as he liked to have a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Swisserland</td>\n",
       "      <td>GPE</td>\n",
       "      <td>\"That may be--but not by sketches in Swisserla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Matrimony</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Matrimony, as the origin of change, was always...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Taylor</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>Matrimony, as the origin of change, was always...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Goddard</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>Mrs. Goddard, and the teachers, and the girls ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Martins</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>Mrs. Goddard, and the teachers, and the girls ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Abbey-Mill</td>\n",
       "      <td>NORP</td>\n",
       "      <td>Mrs. Goddard, and the teachers, and the girls ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Maple Grove</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>I saw a vast deal of that in the neighbourhood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>first</td>\n",
       "      <td>ORDINAL</td>\n",
       "      <td>Always the first person to be thought of!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>London</td>\n",
       "      <td>GPE</td>\n",
       "      <td>It soon appeared that London was not the place...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>John Knightley</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>It would be a great disappointment to Mr. John...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>second</td>\n",
       "      <td>ORDINAL</td>\n",
       "      <td>Another view of man, my second brings,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>the last month</td>\n",
       "      <td>DATE</td>\n",
       "      <td>After such behaviour, as I have witnessed duri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Kitty</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>Kitty, a fair but frozen maid.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Entity Entity_type  \\\n",
       "0                    Weston      PERSON   \n",
       "1                       Son      PERSON   \n",
       "2   F. C. WESTON CHURCHILL.      PERSON   \n",
       "3                     Elton      PERSON   \n",
       "4                    Dixons         ORG   \n",
       "5                      Emma      PERSON   \n",
       "6               Jane Austen      PERSON   \n",
       "7                      1816        DATE   \n",
       "8                   William      PERSON   \n",
       "9                    Hodges      PERSON   \n",
       "10                      one    CARDINAL   \n",
       "11                      two    CARDINAL   \n",
       "12             this morning        TIME   \n",
       "13                Woodhouse      PERSON   \n",
       "14                 Highbury         GPE   \n",
       "15                    Crown         ORG   \n",
       "16          Frank Churchill      PERSON   \n",
       "17                Knightley      PERSON   \n",
       "18                Hartfield      PERSON   \n",
       "19                    Bates      PERSON   \n",
       "20                    Perry      PERSON   \n",
       "21                  Hawkins      PERSON   \n",
       "22                 Randalls         ORG   \n",
       "23                     Cole      PERSON   \n",
       "24                  morning        TIME   \n",
       "25                  evening        TIME   \n",
       "26                 Isabella      PERSON   \n",
       "27       two or three times        DATE   \n",
       "28              Swisserland         GPE   \n",
       "29                Matrimony         ORG   \n",
       "30                   Taylor      PERSON   \n",
       "31                  Goddard      PERSON   \n",
       "32                  Martins      PERSON   \n",
       "33               Abbey-Mill        NORP   \n",
       "34              Maple Grove      PERSON   \n",
       "35                    first     ORDINAL   \n",
       "36                   London         GPE   \n",
       "37           John Knightley      PERSON   \n",
       "38                   second     ORDINAL   \n",
       "39           the last month        DATE   \n",
       "40                    Kitty      PERSON   \n",
       "\n",
       "                                             Sentence  \n",
       "0   \"Who is that gentleman on horseback?\" said she...  \n",
       "1   I hope she is right.--In one respect, my good ...  \n",
       "2   I hope she is right.--In one respect, my good ...  \n",
       "3   \"Something that would do!\" repeated Mrs. Elton...  \n",
       "4   \"And if the Dixons should absolutely deny all ...  \n",
       "5         [Emma by Jane Austen 1816] VOLUME I CHAPTER  \n",
       "6         [Emma by Jane Austen 1816] VOLUME I CHAPTER  \n",
       "7         [Emma by Jane Austen 1816] VOLUME I CHAPTER  \n",
       "8   William did not seem to mind it himself, he wa...  \n",
       "9   William did not seem to mind it himself, he wa...  \n",
       "10  \" They were permitted to go alone; and with a ...  \n",
       "11  \" They were permitted to go alone; and with a ...  \n",
       "12  \"I had a few lines on parish business from Mr....  \n",
       "13  Why had not Miss Woodhouse revived the former ...  \n",
       "14  Why had not Miss Woodhouse revived the former ...  \n",
       "15  \"My father and Mrs. Weston are at the Crown at...  \n",
       "16  \"My father and Mrs. Weston are at the Crown at...  \n",
       "17       \" \"I do not admire it,\" said Mr. Knightley.   \n",
       "18  I think you must know Hartfield enough to comp...  \n",
       "19  \"To be sure we do,\" cried his father; \"Mrs. Ba...  \n",
       "20                             Mr. Perry did say so.   \n",
       "21                           A Miss Hawkins of Bath.   \n",
       "22  Emma found it really time to be at home; the v...  \n",
       "23  Perry tells me that Mr. Cole never touches mal...  \n",
       "24  Either in the morning or evening of every day,...  \n",
       "25  Either in the morning or evening of every day,...  \n",
       "26  Either in the morning or evening of every day,...  \n",
       "27  She read it to him, just as he liked to have a...  \n",
       "28  \"That may be--but not by sketches in Swisserla...  \n",
       "29  Matrimony, as the origin of change, was always...  \n",
       "30  Matrimony, as the origin of change, was always...  \n",
       "31  Mrs. Goddard, and the teachers, and the girls ...  \n",
       "32  Mrs. Goddard, and the teachers, and the girls ...  \n",
       "33  Mrs. Goddard, and the teachers, and the girls ...  \n",
       "34  I saw a vast deal of that in the neighbourhood...  \n",
       "35         Always the first person to be thought of!   \n",
       "36  It soon appeared that London was not the place...  \n",
       "37  It would be a great disappointment to Mr. John...  \n",
       "38            Another view of man, my second brings,   \n",
       "39  After such behaviour, as I have witnessed duri...  \n",
       "40                    Kitty, a fair but frozen maid.   "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities=[]\n",
    "type_entity=[]\n",
    "sentences=[]\n",
    "for sent in sample:\n",
    "    parsed_sentence=nlp(sent)\n",
    "    for ent in parsed_sentence.ents:\n",
    "        if ent.text not in entities:\n",
    "            entities.append(ent.text)\n",
    "            sentences.append(sent)\n",
    "            type_entity.append(ent.label_)\n",
    "Entities=pd.DataFrame({'Sentence':sentences,'Entity':entities,'Entity_type':type_entity})\n",
    "len(Entities)\n",
    "Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A visualisation depicting the number of entities per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x959368c048>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAE9CAYAAAAS3zmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xm4HFW57/HvjwSiQBKZJEwJg4iKAyogKugGZFYZBAVR\nUBD1Ivh4QeQoHgmgOIADMlzvkUEIg6AIiCKKygaPonBAOYpwmAkQpjAlJEwm7/lj1SaVTvfu3tnd\nXbWS3+d58qSrVu3qd3fvfnvVmkoRgZmZ5WeZqgMwM7PF4wRuZpYpJ3Azs0w5gZuZZcoJ3MwsU07g\nZmaZcgJfwkmaLWndquNYUkjaVtI9FT7/npLulzRL0sY9fq53S/r7MOXrSZrVyxhseE7gNSPpXklz\niw/o7OL/73f4s1dLOqC8LyLGR8S9RflZko5dzLiGYpklaV4R49C+fRbnnCN8/tMlfazJ/q9Kmi9p\nt9K+ccW+NXsUTpWTJ04EDoqICRFxS7dOKmlM8ZpNHtoXEddExBtKx9wv6V2l8nsiYkK3YrCRG1t1\nALaIAHaJiKurDqQsIsYPPZZ0N3Bgn2PcETiqyf4AHgeOBS5t2F9rksZExLwRHL8MsA7wz16EQwav\nmS3MNfB6UtOd0v6S/iDpBElPSLpL0g5F2VeBrYBTyrX2ola1vqSDgH2BLxTll0n6vKSfNjzH9yV9\nt4P4XopR0pqS5kiaUNq3uaSHJC0j6UBJ10g6VdJTkm6RNFA6dqKkMyXNkDRd0jENMb0ZeDgiHmkR\nzxXpMH242WtYvGb7lbYPlHR18Xio5vlpSXdKelrSVyS9StJ1RbznSRqzcEj6d0kzi/fgQ6WCcZK+\nU/weD0k6RdJyRdm2ku6R9EVJDwH/scgLm3yluBJ7uHhdVpS0PPB0cdg/Jd3a7IWQ9DpJV0l6XNI/\nJe1RKpsm6SRJVxR/A3+UNKUovqZ07lmSdlepuUjS+cCawK+K8s9J2kDS/NL5W76PkjYs/gaekvSo\npHObxW8jFBH+V6N/wD3ANi3K9geeBw4gJahPAw+Wyq8GDmj4mXnA+sXjs4BjS2WTgNnAhGJ7DPAI\nsMlIYwSuJNXKh7a/D5xYPD4QeBH4TPEc+wBPlJ73cuBkYBywGnAD8PHSuY4CjmkRy3HAmcBuwO2k\nSsk4YD6wZnHMH4D9Sj9zIPD70u88H/gpsDzw+uI1/jWptjsRuBXYpzh+2+J3+QawLLA1MKf0Gp8M\nXAxMAFYEfjEUe+lnjyNd/Y5r8vt8ErgNmAysQLqqOLMh1nVavBYrAA+QvqgFvBmYCWxYlE8DHi32\njwF+DJzT6txFvHeXtu8HtiptbwDMK23/vNX7CFwEHFE8Xg54e9WftSXhn2vg9XRpUcN+svj/wFLZ\nfRFxZqRPwtnAGpJeOcy5mtbmASLiYeBaYK9i107AYxHxt8WI+Rzgo5BqtcDepIQxZEZEnBoR8yLi\nAtKXwE5FO/W2wGER8XxEPAacREryQ3Yh1bJbiohLgVnAxxcjdoBvRMTciPgHKWFfGRH3R8TTpGT+\n5tKx84CpEfFipGakK4G9JAn4BPC5iJgVEc8A32z4XV4sfvZfEfF8kzg+TPrimx4Rc4AvFftgwXvZ\n6j3dFfifiDgvkr+SvgD2LB3z04j4a6Smm/OATRrO0fLvZbhySWsB72HR93Hv4pAXgXUlrRkRL0TE\ndW2exzrgNvB62jVaty8/PPQgIp5NOYMVSTWrxXEOqSZ/BqnmNm34w1u6hNR8szYpKTwSETeXyh9o\nOP4+0iX5FFKN7ZHidxlqnhm6dF8FWC8i/tJBDF8GfgD8ZDHiL79+z5KuRMrbE0vbj0fEc6Xtod9l\nEul3ubn4XSBdEcwvHftIDN/uvWZxvvK5l5O0GumqZThTgC0lDR0nUs36rNIxD5cezyX97XTDZIZ5\nH4HDgK8C/yXpMeDbEXFOl557qeUEXk/takGttOuEalZ+KXCa0pC09wJHLNYTpy+Ti4GPkBJ44xfB\n2g3bk4EZpMvyORGxcotT7wD8tsMYrpQ0HfgUC/+uc0jNI0MmdXK+YawiaVypBj2Z1FzwCKn5ZaOi\nBto0zDbnnkFKxEOmAM9HxGMN7fDN3A/8NiJ2aXPc4sTV7phh38dI/RcHAUjaCrhK0jURcV+z460z\nbkJZsjwCrD+S8iIJXQycD/wlIhpryiMxjdQ+vzPQ2Em1hqSDi07DvYs4riye7xpJ35Y0vujE26D4\nkFOc65cjiOHLwJEN+/4GfEDSyyS9uohxNMYAUyUtW3TG7gj8JCLmA6cDJ0laFUDS2pK2G8G5LwAO\nkzRF0nhSrfX8Dn/258DGkvaRNLaIbzNJG7b7wSL2mQz/9/Nwk3IVPz/s+yhpLy0Y1vk06aqk4xE4\n1pwTeD1drgVjrmcVNdtWyrWik0htsY9L+l6T8jNIH/AnJP2stP9s4A2k5pRONK2JRcS1pKu6P0fE\njIbiPwEbk5oBvgLsUbQvQ6q1r0AaHvcEqcNr9aJNeTtSG3RngaUYbmyI8cTi/0dICbbx6qDx92lX\nG72fVKt/iNQ8cWBE3F2UHU5q9rhe0lOk9vFXdRo/8EPgQlLH652kZPe5TmKLiFmkK5aPFLHNAI4n\nNW0M+7OFo4ELir+P3ZqUfx04tij/bJNzNn0fi7K3ATdImk3qMD54lJUFA5T6woY5IA2BOo3UQbES\ncBfwpeJydQqpjesZFowj/WZEfK2nUVtXSVqH1HE3qeh4G825rgHOKLdvFp2w+0bENiM819uBEyJi\ny9HEZLak6qQNfCwwnTR86H5JuwAXSXp9UR7AxGj3TWC1pDQ55HDgx11I3luQatmL04nYzHzgmLZH\nmS2l2ibwiJhLmuU2tP3LYnD/W4GbSDXvZXB7VnaKySGPUAzpG+W5ziW1Vx8SEc92ITw6HHlittRq\n24SyyA9IqwP3Am8EXgDuJrW1BWm0wBER8Xh3wzQzs0YjSuCSxgK/Au6IiIMlrQBsROrlX4XUVj4+\nInZs8rNuYjEzWwwR0XRoccejUIoRAeeSxrkeWpx0TkTcFBHzi3GvhwDbF4m9WRBd/Xf00UdXPpXV\ncTpOx+kYexnncEYykecMYFVg5xh+Jlng4YlmZj3XUQKX9APgNcB7IuKF0v7NgaeAO4CVSeOQr46I\n2T2I1czMStomcKUF3j8JPMeCdQ6CBdOVjyetPDYLuIoFC+/03MDAQL+ealQcZ3c5zu7KIc4cYoT+\nxzniUSiL/URS9Ou5zMyWFJKI0XZimplZvTiBm5llygnczCxTTuBmZplyAjczy5QTuJlZppzAzcwy\n5QRuZpYpJ3Azs0w5gZuZZcoJ3MwsU07gZmaZqmUCnzRpEpK6+m/SpElV/1pmZl1Vy9UIiyVru86r\nIZpZbrwaoZnZEsgJ3MwsU07gZmaZcgI3M8uUE7iZWaacwM3MMuUEbmaWKSdwM7NMOYGbmWXKCdzM\nLFNO4GZmmXICNzPLlBO4mVmmnMDNzDLlBG5mlikncDOzTDmBm5llygnczCxTTuBmZplyAjczy1Tb\nBC5pOUmnS7pX0tOSbpK0Y6l8W0m3SnpG0u8kTe5tyGZmBp3VwMcC04GtImIi8O/ARZImS1oFuBg4\nClgZuBG4sFfBmpnZAoqIkf+QdDMwFVgV2D8itiz2Lw/MBDaJiNsbfiY6fS5JI46pE4vzu5qZVUkS\nEdE0KY64DVzS6sCGwC3AxsDNQ2URMRe4s9hvZmY9NKIELmkscC7wo6KGvSLwdMNhs4Dx3QnPzMxa\nGdvpgUrtGucCzwOHFrufASY0HDoRmN3sHFOnTn3p8cDAAAMDA51Hama2FBgcHGRwcLCjYztuA5d0\nJjAZ2DkiXij2HcTCbeArAI/hNnAzs64YdRu4pB8ArwHeP5S8C5cAG0vaXdI44Gjgb43J28zMuq9t\nDbwY130v8Bwwr9gdwKci4gJJ2wCnkmrnfwE+FhHTm5zHNXAzsxEarga+WMMIFzMIJ3AzsxHq6jBC\nMzOrBydwM7NMOYGbmWXKCdzMLFNO4GZmmXICNzPLlBO4mVmmnMDNzDLlBG5mlikncDOzTDmBm5ll\nygnczCxTTuBmZplyAjczy5QTuJlZppzAzcwy5QRuZpYpJ3Azs0w5gZuZZcoJ3MwsU07gZmaZcgI3\nM8uUE7iZWaacwM3MMuUEbmaWKSdwM7NMOYGbmWXKCdzMLFNO4GZmmXICNzPLlBO4mVmmnMDNzDLl\nBG5mlikncDOzTDmBm5llqqMELukzkm6Q9JykM0v7p0iaL2mWpNnF/0f1LlwzMxsytsPjHgSOA3YA\nXt5QFsDEiIhuBmZmZsPrKIFHxKUAkjYD1mooFqkmP6+7oZmZ2XC60QYewL2Spks6U9IqXTinmZm1\nMdoEPhPYDJgCvBUYD5w32qDMzKy9TtvAm4qIOcBNxeZjkg4BHpK0QlG2kKlTp770eGBggIGBgdE8\nvZnZEmdwcJDBwcGOjtVI+h4lHQesFREHtChfHZgBvCIiZjeUddzPKanjmEbC/axmlhtJRETTpNhR\nDVzSGGBZYAwwVtI44F+kZpOngDuAlYGTgKsbk7eZmXVfp23gXwbmAkcC+xaPjwLWB64EZgH/DTwH\nfLj7YZqZWaMRNaGM6onchGJmNmLDNaF4Kr2ZWaacwM3MMuUEbmaWKSdwM7NMOYGbmWXKCdzMLFNO\n4GZmmXICNzPLlBO4mVmmnMDNzDLlBG5mlikncDOzTDmBm5llygnczCxTTuBmZplyAjczy5QTuJlZ\nppzAzcwy5QRuZpYpJ3Azs0w5gZuZZcoJ3MwsU07gZmaZcgI3M8uUE7iZWaacwM3MMuUEbmaWKSdw\nM7NMOYGbmWXKCdzMLFNO4GZmmXICNzPLlBO4mVmmnMDNzDLlBG5mlqmOErikz0i6QdJzks5sKNtW\n0q2SnpH0O0mTexOqmZmVdVoDfxA4DjijvFPSKsDFwFHAysCNwIXdDNDMzJob28lBEXEpgKTNgLVK\nRXsA/4iInxXlU4GZkl4dEbd3OVYzMysZbRv4xsDNQxsRMRe4s9hvZmY91FENfBgrAo827JsFjG92\n8NSpU196PDAwwMDAwCif3sxsyTI4OMjg4GBHxyoiOj6xpOOAtSLigGL7e8DYiDikdMzfga9ExCUN\nPxudPpekjmMaiZH8rmZmdSCJiGiaFEfbhHILsEnpiVYANij2m5lZD3U6jHCMpJcBY4CxksZJGgNc\nAmwsaXdJ44Cjgb+5A9PMrPc6rYF/GZgLHAnsWzw+KiJmAh8AjgeeADYF9u5BnGZm1mBEbeCjeiK3\ngZuZjVgv28DNzKwiTuBmZplyAjczy5QTuJlZppzAzcwy5QRuZpYpJ3Azs0w5gZuZZcoJ3MwsU07g\nZmaZcgI3M8uUE7iZWaacwM3MMuUEbmaWKSdwM7NMOYGbmWXKCdzMLFNO4GZmmXICNzPLlBO4mVmm\nnMDNzDLlBG5mlikncDOzTDmBm5llygnczCxTTuBmZplyAjczy5QTuJlZppzAzcwy5QRuZpYpJ3Az\ns0w5gZuZZcoJ3MwsU07gZmaZ6koClzQo6VlJsyTNlnRrN85rZmatdasGHsDBETEhIsZHxGu7dF4z\nM2uhm00o6uK5zMysjW4m8K9LelTSHyS9u4vnNTOzJrqVwL8ArA+sBfwQuFzSel06t5mZNTG2GyeJ\niBtKm+dI2gfYGTi1fNzUqVNfejwwMMDAwEA3nt7MbIkxODjI4OBgR8cqIroegKQrgCsi4pTSvuj0\nuaTeNKf34nc1M+slSURE06Q46iYUSRMlbS9pnKQxkvYFtgKuHO25zcystW40oSwLfBXYCJgH3Abs\nGhF3duHcZmbWQk+aUJo+kZtQzMxGrKdNKGZmVg0ncDOzTDmBm5llygnczCxTTuCjMGnSJCR19d+k\nSZOq/rXMLBMehTIKucRpZvnyKBQzsyWQE7iZWaacwM3MMuUEbmaWKSdwM7NMOYGbmWXKCdzMLFNO\n4EuBHCYc5RBjTnHa0sETeUbBcXYvzhxihHzitCWHJ/KYmS2BnMDNzDLlBG5mlikncDOzTDmBm5ll\nygnczCxTTuBmZplyAjdbAuUy4SiXOOvKE3lGwXF6Ik+3OM7uWpImRnkij5nZEsgJ3MwsU07gZmaZ\ncgI3M8uUE7iZWaacwM3MMuUEbmbWRl3Hq3sc+Cg4To8D7xbH2V1LUpweB25mtgRyAjczy5QTuJlZ\nprqSwCWtJOkSSc9IukfSPt04r5mZtTa2S+c5DXgOWA14C/BLSX+LiFu7dH4zM2sw6lEokpYHngRe\nFxF3FfvOBh6MiC+VjvMolA4tjXHmECM4TsfZXXUYhfJq4MWh5F24Gdi4C+c2M7MWutGEsiIwq2Hf\nLGB844G9+hbrVNXP3ynH2T05xAiOs9uWlji7kcCfASY07JsIzC7vaHUJYGZmi6cbTSi3A2MlbVDa\n9ybgli6c28zMWujKVHpJ5wMBHEQahXI58A6PQjEz651uTeT5DLA88ChwLvBpJ28zs97q22JWZmbW\nXZ5Kb2aWKSdwW4SkVWsQw2UN28c0bN/Q34iWfJJqnw+UbFN1HHVR+zcsJ5I2l/SV0vatku4u/du0\nyviGSHqiYft3DYfc3cdwWtm6YfvQhu3X9CuQpYGkccCLVcfRgeWAq6oOYoikiZLeImmReS/90K21\nUHqunBhbiIg4ri/BtPZ54Mel7TWBPYrHmwFHAnv1O6gmlm3YfnPDdh3H7DfGVJvOG0mfj4gTS9vb\nRcRVpe3vRMRh1UQ3InV835upRZySdgEuAl4OzJa0W0Rc3dcYcunElDRtmOKdgJUiYky/4mlG0r3A\nayPi2WL7yYhYqXg8DrgtItarMESKWGZFxITS9hMRsXKr8irkEOOQnGJtpfj7nFv1Z6idOsUp6Sbg\nzOLfQcCHIuId/Ywhmxp4RHy0cZ+k9wLHAY8B/6fvQS1qFdKqjEMGSo9fBCpvW87IspI+zoLa1jhJ\nB5TK6/S321gjbLdtw2jTFl954i5ZPyJOAZB0KnBUvwOo04egY0UnxleB1YFjgHMjYn61UQEwk9Q2\neytARNxcKnst8HgVQTXxMknnlLZXaNge1++AmvgLsF9p+3rgow3lddF4GdtuuxKS/kDrWOrUH/Yv\nWsepYcr67aXXLCL+Janv+TSrBC5pC+B40gqIXwNOj4g6dbxcAnxP0q4R8VJNXNLLgW8DP6sssoV9\nrWH7+DbbfRcRA1XHMAKStB4LatrLNGzXpQZ+epvyH/YlivYqb2bs0PKSri1tj2/YJiLe1csAcmoD\n/wXwNuBbpBtIPNt4TNW1cEkrAleTOi9/DTwMrAFsDzwEbB0Rs1ufwXIkaT6pVtgqUUcd2mzbkfS6\niPhn1XEMR9JKwD4RcVoNYtm/3TERcXZPY8gogZeTc2PQoiYfEknLkS79tyW1eT8O/A44JyKerzK2\nIZJeDfwIeD1wE/DxiLin0qAaSJo3XDE1eb9zJ2kV4MPA/sAbIqIOzWcLkTQG2IUU4y7AHRHxhmqj\nak/Ssr1uIcgpgU9pd0xE3NePWBaXpFUjYmYN4vgNad2a84F9gRUiYrdqo1qYpEeBJ4CzgcuARb78\nGm4iUhlJf88hoQwp2mrfR6po7ExqSv0W8P2IeKjK2MokvYWUtPcmDdUbB+wZEZdXGlgbxUiZTwFH\nRMQ6PX2uXBJ4WfECrQw8WW5rrouiVvPkUJOOpNVJY8APiohKBvyXSZoJrB0RzxXNPrdHxJpVx1VW\nJJmdSElmS+DnpKuYP1YaWBOSZtfhfW1H0mak13PopuM/JX2JXwS8MSIerSq2MklHkOLcEPgNKcaf\nA3cBb6pRnBsBZ5CWz76DFPNGwPeBB4ETI+KingYREdn8I7WBD5KG5M0r/r8W2KLq2Ir4tgDuL2J7\nFHgXcBjpDkUXAZtXHWMR56yG7SeqjqlNvK8g1Wj+k7T+/Gurjmm417Ou/4D5pCG3+wBjS/sfAl5Z\ndXxN4vwgRSWzpnH+GjiLVNGYRvqC+Qfwnn7FkM0oFElvJ30bTwOmkt7MNYAPAVdJ2j4irqsuQgBO\nJF3yn0e69LuY9IZuGhG3VxlYg3GSji1tv7xhm4hoN/O1n4Y6CaFe44CHNI5GWET0eDRCh44lDcU8\nHdhV0nnAr6jPsLwh25Bqs6cD35X0Y1ItvG5xvhV4f0Q8X7z/s4ApEfFAvwLIpgmlWK/j0og4uUnZ\nocDuEVHpIjfFGiOrRsT8ojNzLqnG8ESbH+0rST+izYchIj7en2iaKyZz7ET6InwX6RJ6WkT8ocq4\nmpH0LPDp4Y6JHo9GGAlJ7yIlyL1IV7ErArtEROOaOJWStDzwAVKsW5M6r6cCp0VE5XMq2s3A7UsM\nGSXwp4E1I2JOk7IVgRlR8+nfdVLuIZe0JQtP5LguKh5fL+lh4EnSFdelLDzDFYCIqMOiW1lMlW+m\nmJ+wBwtGTd0UEZtXG1VzktYhXT3sB0yOiOUrDglJzwPfLO06AjihfEyvr2RzSuBPAetGxFNNylYC\n7o2Iif2PbKE4XmDhxaw+BFxYPiYi9qNikj4NvDOK5QkkzSXNIhXpzkpfiIgzKgyx1bDR8jjriJoM\nI8ylE3M4ktYCPhIR32x7cMUkvS0iKp+JK+msNodERBzQ5phRyaYNHLiG1CHY7BvtMFJnZtXazXCs\ni/1Z+JL/+YiYDCBpE+D/kXrXKxMRdZra3c6w73NdJshImtzmkAv6Ekgbkjqp5FSewKtuZoS8auCv\nI41C+BPwExZ0Yu4FvAPYsiYfkrHAR4DtSBN5ZpIm8kyrulliiKSHI2JSafuPEfHO4rGAhyNi9coC\nXALUcYLMMDNGh5JARETllbpizZZmgrSm0Mp1ufoCkDTAwp/330aflpXNJoEDSNqA1InxHkovFnBM\nRNxZYWgASJpIGimzLql3f+hLZidgOml40dOVBViQ9Ayw+jD9CQ9HxIr9j2yhOKbRvqO18uaosrpP\nkClmNDZ6GXAw8AXg+ojYpb9RdUbSG0krj74D+FZEnNDmR3quGKhwEbAj8GcWfN63IOWBPSPihV7G\nUPm37UhEmnm3yLKyNfJ10pfKNuXkWCTFC4vygyuKrewfpPVZLmlStgNwS3/DaaryL+ROtZggsx3p\nw/3dqMnEk4h4aXmCIpl/grQE6p3ArhHxp6pia0XShqThjzsA3yO109dlPaGppIT9qvLQwaLD9aek\nlVK/2NMI+jXgfLT/gCmk2YND28uT2pwvA/4NGFODGGeQesibla0LPFR1jEUse5NqC7sByxT7lgF2\nL/bvU4MYK49hBLFmMUGmiEmkL5u7SLXGvk06GWGck0k3SniaNNJj5apjahLjvbSYVAZsDNzX8xiq\nfhFG8GL9ljTWe2j7rOKP8ATgf4DjaxDjnFZfJKSrnTlVx1iK53DgGeCF4ovnBWA2af2GOsSXxezG\nItapxd/iHNIopPcV7/eMOiVwYE/S1dVfgfdWHc8wcZ5SJO6T6vT6NYlzzlAFqEnZMv34vGfTBl4s\nbrReRMyRtAKpxrNVRNwo6TXAFRGxfsUx/jdweJTuh1gq24G0NkJtFj2SNAF4OwtWTbwuatBGD3kO\nzSsmyOxPSpS1myBTdGI+TpoC3nTp5ahBv0IR5xzgKVr0g0QxaqpKkm4nNelc36TsbaQbzWzYyxhy\nagNfLha0K28GzI6IGwEi4jZJdbhd2XeAcyQdAlwSaUbmMqTJEicDX6o0ugYRMYv0Ya6jMZKGZt81\nFRG/72M8bUXEtcC1xfu/OymZ/1pSXSbIHEv9pqM3s3XVAXToh8A0SR8eykUAkjYFzgH+o9cB5FQD\n/yvwfyNiUNJ3SLMy9y7KVgP+HqWhcVWRdDjpknocqUNzVdJSqMdGDXrOc1GsB34fw98kodIrrkbF\nUNetSCtlPkEa9vok8NHIYIKMjZykk0n3472fBaNQJgM/AA6JHifYnBL4rqSFou4m3XdyYOjSRdIn\nSIvKvL/CEF8iaTxpuNPQUMfritqudSin6enF2PkzSDXuB0ht32uR7sw0DTig1x/kTkhq+4UXNVie\nQAvfvLqpiDizH7F0QtKrWHADl5nA7yPijr48dw3+rjpWjAPfhLRmwz2l/e8EnoqIOgx/sy7ILIF/\nirTe+4ci4obS/s1IsxtPjIgfVBVfKZ4sbv0mqd0kmIiKF66Dl+IcLoFGRGzb0xhySuDDkbRLRPyy\n6jisO3LqxJT0n8A3IuIXTcreC3wxipmutuSQdGCLorWAzwLLR48X3coqgReD+t8I3BkRNxf73g8c\nDawTEa+sMj5bOhXLCE+JJhNMiua06RGxUv8ja61YifAVpCvXRW4QXgfFInWbk/oUHgduiIgnq42q\ntWL5hC8CB5Em7h0bPV4bPJsFgyR9DPgn6Y70N0r6rKRLSbOzziRN9DGrwphmyRug2F+bz5mkrSVd\nTxrz/wAwW9L1knp6qT9Skv6d1JfwC9LoriuAGZKOrjSwJiRNkHQcaUbr6sBbIuKTvU7ekNcwwiNJ\nHZW/KmrdF5PuPbdX1GSRKFtqLdtmyGMtPmfF8LYrSHe6OZIFna17AJdLene5Db8qkj4IHEpaFO6y\niPhXsc7MbsApkm6LiAuHPUkfFFcxnyNNihskLajX1364bJpQJD0dxXrfRa//s8B4J2+rmqR7ab/w\n1nr9iaY1SRcCt0XEIrXYoma7cUR8sP+RLRLLVcDZEXFuk7J9SaN6Kr9ikPQI6erqBOC/mh3T67kK\nOSXwbO52Y1ZHkqaTbgA+o0nZmqTVCNfuf2SLxPIYsFE0uRVh0S5+R0RUPnGvgy/uns9VyCmBzwMe\nLO1aq2G7FtNrzeqq3dDMuoz86SDObIaY9lot2uY6VPm4T7MlXF1qc5K0Hq37FFour7C0yaYGbmaj\n0+QqdqFiYI2oxx15sphwVAeVv1mdknRZROxa2j6m3Bkj6YaI2Kya6MyykMVVbOR1P9RKZVMDb9eJ\nWZf2O7NcSVo1ImZWHUc7nnW9QM7fdK1uzGpmw5C0SrHM8dD26sUKn/cM82N9JWlDSR+Q9KbSvvdL\nupF0Mxcj7wTuhG02ApK2kHQ/8CjwsKR3SToMuANYm7SiXuU867pz2bSBk2a7lZeZHNewndPvYlaF\nE0lLMp+pmifZAAADBUlEQVRHWvr2YtINrjeNiNurDKyBZ113KKc28EEW3Aaqae90RORyJw+zvisW\n3Vq1uFPUcsBc0j0nF5kwUyXPuu5cTrXWXYAvA68HbiLdxPj5akMyy8rYiJgPEBEvFAMDapW8Cy9V\n0CIiJM118m4upwR+MrApcCXwAdISk4dWGpFZXl4m6ZzS9goN27W4qTEpruml7YkN2551XcipCeUh\n0jKND0laB7i2DgsEmeWik6VYI+KYfsQyHEnvbndMRFzTj1jqLqcE7sWszEapWJb1I8B2LLiH4++A\naTk0UxTDH3eMiCuqjqUOckrgc0nt4EPtY5cCu7Jwe1lPl240y5mkicBvgHWBX7HgLuo7AdOB90TE\n05UFOAxJbySNnNmXdAON1SoOqRZySuD3UvHSjWY5k3QaaQz1ByNiTmn/iqRbgN0XEQdXFV8jSa8k\nJez9SLdSDNK9Js+MiOeqjK0uskngZjY6kmaQ1gOf3qRsXeC6iFij33E1krQXKWnvCNwKnA9cAPwZ\neFNEPFpheLWS0ygUMxudibRejfABoC5rbF9IuonxByPikqGdaUi4leU8ld7MRuYuWq9IuC1wdx9j\nGc4BwN+Bn0j6s6RDi+YUNxc0cAI3W3p8BzinWCRqGUijOiTtCfyoKK9cRPwoIrYBNgB+SZrv8SCw\nGrCzJK8FXnAbuNlSRNLhwFRgHGkI4arA88CxEXFChaENS9I7SaNQ9gLmRsRaFYdUC07gZksZSeOB\nd7BgHPh1ETGr2qgWKJL1+yLi35qUfRN4MiK+0f/I6sedmGZLmYiYDfy66jiG8SXg1BZlVwOf6WMs\nteYauJnViqQHgckRMa9J2VhgekSs2f/I6sedmGZWNxOA5VqULQv41okFJ3Azq5vbgO1blG1flBtu\nAzez+vku8P+L4YKXFjegWAbYjdQ2flil0dWIE7iZ1UpEnC9pEun2b+MklYc7Hh0RF1QaYI24E9PM\naknSBODtwCqkqfW1Gu5YB07gZmaZciemmVmmnMDNzDLlBG5mlikncDOzTP0vvxYtjsPbPH0AAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x959368cdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.subplot(111)\n",
    "Entities.Entity_type.value_counts().plot(kind='bar',title='Entity Type/ Number of entities',color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The confusion matrix that is showing truly classified examples and false classifications. Most classifications for different classes are with decent accuracy, the rest are so small in sample, including them to judge spacy's NER capabilities won't hold any significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                  True Label\n",
    "\n",
    "| `PERSON` | `NORP` | `FACILITY` | `ORG` | `GPE` | `LOC` | `PRODUCT` | `EVENT` | `WORK_OF_ART` | `LAW` | `DATE` | `PERCENT` | `TIME` | `MONEY` | `QUANTITY` | `ORDINAL` | `CARDINAL` | \n",
    ":----: |---\n",
    "`PERSON` |22 | | | 3| | | | | |1 | | | | | | |\n",
    "`NORP` | | | | | | | | | | | | | | | | |\n",
    "`FACILITY` | | | | |1 | | | | | | | | | | | |\n",
    "`ORG` | | | |2 | | | | | | | | | | | | |\n",
    "`GPE` |1 | | | | 1| | | | | | | | | | | |\n",
    "`LOC` | | | | | | | | | | | | | | | | |\n",
    "`PRODUCT` | | | | | | | | | | | | | | | | |\n",
    "`EVENT` | | | | | | | | | | | | | | | | |\n",
    "`WORK_OF_ART` | | | | | | | | | | | | | | | | |\n",
    "`LAW` | | | | | | | | | | | | | | | | |\n",
    "`LANGUAGE` | | | | | | | | | | | | | | | | |\n",
    "`DATE` | | | | | | | | | |4 | | | | | | |\n",
    "`TIME` | | | | | | | | | | | | 6| | | | |\n",
    "`PERCENT` | | | | | | | | | | | | | | | | |\n",
    "`MONEY` | | | | | | | | | | | | | | | | |\n",
    "`QUANTITY` | | | | | | | | | | | | | | | | |\n",
    "`ORDINAL` | | | | | | | | | | | | | | |1 | |\n",
    "`CARDINAL` | | | | | | | | | | | | | | | |3 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section will be looking at how to determine, for a given author or authors, whether there are differences in portrail of characters based on gender. \n",
    "\n",
    "Our final task in this notebook is to define a function that guesses the gender of a character based on his or her name.  \n",
    "\n",
    "We have provided a csv file called `names.csv` that contains several thousand male and female names with information about how frequent each name is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recognizing the gender of the identified PERSON  class entity\n",
    "\n",
    "Create_gender_map() function as shown in Topic 7, extracts the male and female names by comparing occurence of a name and comparing between the polarity of its occurence in the specific gender. Input file to the function is the provided file 'names.csv'.\n",
    "\n",
    "A Gender Guesser function is created which inputs a string and gender_map to return whether the string name is male female or unknown. The code is a rule based architecture, where the function checks whether a single word word is passed and compares with gender map to get entity gender labels.\n",
    "\n",
    "If the length of the name entered is greater than 1, the underlying condition checks whether the name is with a surname, extracts the first name and again checks from gender map for the name. Titles have been been defined for male and female class which can signify gender such as Lady or mr. are extracted from a predefined list to extract names with titles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novel Used: Alice in the wonderland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to create gender map from names.csv file\n",
    "def create_gender_map(dict_reader):\n",
    "    names_info = defaultdict(lambda: {\"gender\":\"\", \"freq\": 0.0})\n",
    "    for row in input_file:\n",
    "        name = row[\"name\"].lower()\n",
    "        if names_info[name][\"freq\"] < float(row[\"freq\"]): # is this gender more frequent?\n",
    "            names_info[name][\"gender\"] = row[\"gender\"] \n",
    "            names_info[name][\"freq\"] = float(row[\"freq\"])\n",
    "    gender_map = defaultdict(lambda: \"unknown\")\n",
    "    for name in names_info:\n",
    "        gender_map[name] = names_info[name][\"gender\"]\n",
    "    return gender_map\n",
    "os.chdir('C://Users//cmm//Desktop')\n",
    "\n",
    "input_file = csv.DictReader(open('names.csv')) ## Importing our names.csv file\n",
    "gender_map = create_gender_map(input_file)    ## Import the gender map\n",
    "#### Male homonyms\n",
    "male_title=['mr.','sir','monsieur','captain','chief','master','lord','baron','mister','mr','prince','king']\n",
    "#### Female homonyms\n",
    "female_title=['mrs.','ms.','miss','lady','madameoiselle','baroness','mistress','mrs','ms','queen','princess','madam','madame']\n",
    "\n",
    "\n",
    "def gender_guess(name,gender_map):                   #Identifying entries in the names.csv database#\n",
    "    if (len(name.split()))==1:\n",
    "        if name.lower() in gender_map.keys():\n",
    "            return gender_map[name]\n",
    "        else:\n",
    "            return('unknown')\n",
    "    \n",
    "    if(len(name.split()))>1:                        \n",
    "        name_array=name.lower().split()\n",
    "        if name_array[0] in gender_map.keys():\n",
    "            return gender_map[name_array[0]]\n",
    "        \n",
    "        \n",
    "        for title in name_array:                     #Recognising titles of entries# \n",
    "            if title in male_title:\n",
    "                return 'male'\n",
    "            elif title in female_title:\n",
    "                return 'female'\n",
    "            else: \n",
    "                return('unknown')\n",
    "                break\n",
    "        \n",
    "def named_entity_counts(document,named_entity_label):    \n",
    "    \n",
    "## Function that outputs a Counter object of human entities found\n",
    "\n",
    "    occurrences = [ent.string.strip() for ent in document.ents \n",
    "                   if ent.label_ == named_entity_label and ent.string.strip()]\n",
    "    return Counter(occurrences)\n",
    "\n",
    "alice = gutenberg.raw(fileids='carroll-alice.txt')\n",
    "parsed_alice=nlp(alice)\n",
    "text = parsed_alice    ### Parsing Alice in the wonderland by Lewis Carroll\n",
    "entity_type = 'PERSON' ## Type of entry\n",
    "number_of_entities = 10  ### Control over obtaining number of defined type entities\n",
    "Entities=pd.DataFrame(named_entity_counts(text,entity_type).most_common(number_of_entities),columns=[\"Entity\",\"Count\"])\n",
    "entity=[]\n",
    "for char in Entities['Entity']:\n",
    "    entity.append(gender_guess(char.lower(),gender_map))\n",
    "Entities['Pred_Gender']=entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Count</th>\n",
       "      <th>Pred_Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>388</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gryphon</td>\n",
       "      <td>32</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Queen</td>\n",
       "      <td>27</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mouse</td>\n",
       "      <td>25</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rabbit</td>\n",
       "      <td>20</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bill</td>\n",
       "      <td>12</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dormouse</td>\n",
       "      <td>8</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dinah</td>\n",
       "      <td>8</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>William</td>\n",
       "      <td>5</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Beau</td>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Entity  Count Pred_Gender\n",
       "0     Alice    388      female\n",
       "1   Gryphon     32     unknown\n",
       "2     Queen     27      female\n",
       "3     Mouse     25     unknown\n",
       "4    Rabbit     20     unknown\n",
       "5      Bill     12        male\n",
       "6  Dormouse      8     unknown\n",
       "7     Dinah      8      female\n",
       "8   William      5        male\n",
       "9      Beau      4        male"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Gender classifier for different entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Male type Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n"
     ]
    }
   ],
   "source": [
    "names=['harry','abdul','homer','gary','robert','wayne','lionel']\n",
    "for name in names:\n",
    "    print(gender_guess(name,gender_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Female type entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female\n",
      "female\n",
      "female\n",
      "female\n",
      "female\n",
      "female\n",
      "female\n"
     ]
    }
   ],
   "source": [
    "names=['martha','holly','nicole','catherine','ruth','april','christina']\n",
    "for name in names:\n",
    "    print(gender_guess(name,gender_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For first and last names given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female\n",
      "female\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n"
     ]
    }
   ],
   "source": [
    "names=['Liz Lemon','Leslie Knope','jesus navas','Robert Lewandowski','Anthony Martial','Wesley Sneijder']\n",
    "for name in names:\n",
    "    print(gender_guess(name,gender_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For names with titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male\n",
      "female\n",
      "male\n"
     ]
    }
   ],
   "source": [
    "print(gender_guess('Sir Alex Ferguson',gender_map))\n",
    "print(gender_guess('Lady McElroy',gender_map))\n",
    "print(gender_guess('Captain Subash Chandra boBe',gender_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The program returns 'unknown' if the gender of the entity can't be determined by the function created. This error is a result of the name not being in the names.csv folder or doesn't have a gender bisecting title attached to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown\n",
      "unknown\n",
      "unknown\n"
     ]
    }
   ],
   "source": [
    "print(gender_guess('Liam Neeson',gender_map))\n",
    "print(gender_guess('Mahatma Gandhi',gender_map))\n",
    "print(gender_guess('Pricella McCartney',gender_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at how it is possible to capture apspects of the way in which characters are portrayed, in terms of features. Each character in a novel will be represented in terms of a feature set. For example, one option is that the features are the verbs that the character is the object of (giving a rough sense of what the character does).\n",
    "\n",
    "For each character, we will collect a set of features and represent the feature set associated with a character as a special kind of dictionary called a `Counter`. Each feature is used as a key and the counter maps that feature to a weight which could, for example, be a count indicating how many times that feature has been seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gutenberg electronic text archive\n",
    "[Project Gutenberg electronic text archive](http://www.gutenberg.org/) contains around 75,000 free electronic books. We have made 14862 of the text available to you. \n",
    "\n",
    "\n",
    "To access these texts run the following cell.\n",
    "\n",
    "If you are working on your own machine you will need to do the following:\n",
    "- download and unzip the file `\\\\ad.susx.ac.uk\\ITS\\TeachingResources\\Departments\\Informatics\\LanguageEngineering\\resources.zip'`\n",
    "- update the directory in the following cell, changing the string\n",
    "`'\\\\ad.susx.ac.uk\\ITS\\TeachingResources\\Departments\\Informatics\\LanguageEngineering\\resources/data/gutenberg_eng'` to be the location of the directory within the resources folder that contains \"authors.p\" and \"cleaned_meta_gutenberg\"\n",
    "\n",
    "There are 784 authors whose work have been mentioned in the gutenberg corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GutenbergCorpus import GutenbergCorpusReader as gcr\n",
    "reader = gcr.GutenbergCorpusReader('C://Users//cmm//Desktop//NLP//resources//data//gutenberg_eng') \n",
    "authors = reader.get_authors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of authors mentioned in the Gutenberg corpus are: 784\n",
      "Miller, Alice Duer: 7\n",
      "Sayce, A. H. (Archibald Henry): 8\n",
      "Barbour, Ralph Henry: 19\n",
      "Casanova, Giacomo: 39\n",
      "Locke, William John: 11\n",
      "Lowndes, Marie Belloc: 14\n",
      "Nietzsche, Friedrich Wilhelm: 11\n",
      "Hergesheimer, Joseph: 11\n",
      "Pierson, Clara Dillingham: 7\n",
      "Rockwood, Roy: 10\n",
      "Shelley, Mary Wollstonecraft: 7\n",
      "Farnol, Jeffery: 14\n",
      "Richards, Laura Elizabeth Howe: 35\n",
      "Curwood, James Oliver: 24\n",
      "Maugham, W. Somerset (William Somerset): 14\n",
      "Boothby, Guy: 16\n",
      "Frey, Hildegard G.: 10\n",
      "Duellman, William Edward: 14\n",
      "Stretton, Hesba: 7\n",
      "Gibbon, Edward: 17\n",
      "Porter, Eleanor H. (Eleanor Hodgman): 14\n",
      "Goldfrap, John Henry: 25\n",
      "Anstey, F.: 18\n",
      "Pater, Walter: 10\n",
      "Cooper, James Fenimore: 36\n",
      "Symonds, John Addington: 17\n",
      "Roberts, B. H. (Brigham Henry): 12\n",
      "Burroughs, Edgar Rice: 27\n",
      "Buchan, John: 12\n",
      "Loti, Pierre: 13\n",
      "Becke, Louis: 40\n",
      "Maclaren, Alexander: 20\n",
      "Eastman, Charles Alexander: 8\n",
      "Sudermann, Hermann: 16\n",
      "Butler, Ellis Parker: 22\n",
      "Steele, Richard, Sir: 10\n",
      "Black, William: 19\n",
      "Patchin, Frank Gee: 15\n",
      "Mitton, G. E. (Geraldine Edith): 11\n",
      "Kerr, Robert: 17\n",
      "Wesley, Joseph: 7\n",
      "Ferber, Edna: 10\n",
      "Besant, Walter: 15\n",
      "Stables, Gordon: 25\n",
      "Morris, Gouverneur: 7\n",
      "Benson, E. F. (Edward Frederic): 23\n",
      "Tomlinson, Everett T. (Everett Titsworth): 8\n",
      "Palacio ValdÃ©s, Armando: 7\n",
      "Johnson, Owen: 10\n",
      "Carleton, William: 21\n",
      "Hawthorne, Nathaniel: 95\n",
      "Doyle, Arthur Conan: 62\n",
      "Synge, J. M. (John Millington): 8\n",
      "Chapman, Allen: 24\n",
      "Bailey, Arthur Scott: 40\n",
      "Williamson, A. M. (Alice Muriel): 33\n",
      "Thackeray, William Makepeace: 36\n",
      "Swinburne, Algernon Charles: 20\n",
      "MacDonald, George: 64\n",
      "Moody, Dwight Lyman: 13\n",
      "Spearman, Frank H. (Frank Hamilton): 8\n",
      "Maspero, G. (Gaston): 11\n",
      "Fielding, Henry: 15\n",
      "Mulford, Clarence Edward: 7\n",
      "Nicholson, Meredith: 11\n",
      "Young, Clarence: 15\n",
      "Baring-Gould, S. (Sabine): 31\n",
      "Bourrienne, Louis Antoine Fauvelet de: 17\n",
      "Reeve, Arthur B. (Arthur Benjamin): 14\n",
      "Woolson, Constance Fenimore: 12\n",
      "Luther, Martin: 15\n",
      "Donnell, Annie Hamilton: 8\n",
      "Miller, Alex. McVeigh, Mrs.: 10\n",
      "Freeman, Lewis R. (Lewis Ransome): 8\n",
      "Daudet, Alphonse: 16\n",
      "Dell, Ethel M. (Ethel May): 16\n",
      "Duncan, Norman: 11\n",
      "Gorky, Maksim: 8\n",
      "Poe, Edgar Allan: 12\n",
      "Richmond, Grace S. (Grace Smith): 15\n",
      "Herrick, Robert: 11\n",
      "O'Donnell, Elliott: 8\n",
      "Wister, Owen: 12\n",
      "Leacock, Stephen: 15\n",
      "Mahan, A. T. (Alfred Thayer): 13\n",
      "Leland, Charles Godfrey: 8\n",
      "Sheldon, Georgie, Mrs.: 7\n",
      "Farjeon, B. L. (Benjamin Leopold): 19\n",
      "Montaigne, Michel de: 22\n",
      "Sinclair, Bertrand W.: 7\n",
      "Wood, Henry, Mrs.: 23\n",
      "Harben, Will N. (Will Nathaniel): 9\n",
      "Bunyan, John: 10\n",
      "Mitford, Bertram: 27\n",
      "Oliphant, Mrs. (Margaret): 27\n",
      "MoliÃ¨re: 22\n",
      "Homer: 14\n",
      "Steel, Flora Annie Webster: 20\n",
      "Pinero, Arthur Wing: 9\n",
      "Lynde, Francis: 17\n",
      "Page, Thomas Nelson: 22\n",
      "Marquis, Don: 8\n",
      "Douglas, Alan, Captain: 10\n",
      "Stratton-Porter, Gene: 11\n",
      "Fox, John: 12\n",
      "Walton, Bryce: 8\n",
      "Crane, Stephen: 16\n",
      "Roosevelt, Theodore: 17\n",
      "Wirt, Mildred A. (Mildred Augustine): 24\n",
      "Hendryx, James B. (James Beardsley): 10\n",
      "Unknown: 102\n",
      "Chase, Josephine: 23\n",
      "Hume, David: 11\n",
      "Shoghi, Effendi: 17\n",
      "Irving, Washington: 19\n",
      "Gaskell, Elizabeth Cleghorn: 19\n",
      "Martineau, Harriet: 15\n",
      "Caine, Hall, Sir: 18\n",
      "Jameson, Mrs. (Anna): 10\n",
      "Shakespeare (spurious and doubtful works): 9\n",
      "Holyoake, George Jacob: 8\n",
      "Fox, Frank: 8\n",
      "Sedgwick, Anne Douglas: 13\n",
      "Pinkerton, Allan: 7\n",
      "Conwell, Russell H.: 11\n",
      "Holley, Marietta: 16\n",
      "Peck, George W. (George Wilbur): 10\n",
      "Rinehart, Mary Roberts: 27\n",
      "Leighton, Robert: 8\n",
      "Wells, Carolyn: 42\n",
      "Stephens, Ann S. (Ann Sophia): 13\n",
      "Shaw, Bernard: 46\n",
      "Hope, Anthony: 31\n",
      "Schoolcraft, Henry Rowe: 10\n",
      "Fern, Fanny: 8\n",
      "Moodie, Susanna: 13\n",
      "Pohl, Frederik: 8\n",
      "Wallace, Edgar: 16\n",
      "Vigny, Alfred de: 8\n",
      "Gregory, Jackson: 10\n",
      "Ransome, Arthur: 7\n",
      "Henty, G. A. (George Alfred): 99\n",
      "Muir, John: 9\n",
      "Wood, William Charles Henry: 11\n",
      "Phillips, Rog: 7\n",
      "Hurll, Estelle M. (Estelle May): 13\n",
      "Newman, John Henry: 11\n",
      "Molesworth, Mrs.: 56\n",
      "Wade, Mary Hazelton Blanchard: 20\n",
      "France, Anatole: 26\n",
      "May, Sophie: 21\n",
      "Optic, Oliver: 53\n",
      "Darwin, Charles: 27\n",
      "Bates, Arlo: 12\n",
      "Beach, Rex: 15\n",
      "Cullum, Ridgwell: 17\n",
      "Coolidge, Susan: 12\n",
      "Schubin, Ossip: 10\n",
      "Smollett, T. (Tobias): 9\n",
      "Cicero, Marcus Tullius: 11\n",
      "Norris, Kathleen Thompson: 12\n",
      "Johnston, Annie F. (Annie Fellows): 38\n",
      "Ward, Artemus: 8\n",
      "Rice, Alice Caldwell Hegan: 10\n",
      "Wilde, Oscar: 20\n",
      "Finley, Martha: 32\n",
      "Comstock, Harriet T. (Harriet Theresa): 10\n",
      "Marsh, Richard: 20\n",
      "Meredith, George: 107\n",
      "Schopenhauer, Arthur: 11\n",
      "Sue, EugÃ¨ne: 42\n",
      "Smiles, Samuel: 11\n",
      "Gosse, Edmund: 9\n",
      "Duncan, Sara Jeannette: 8\n",
      "Vance, Louis Joseph: 14\n",
      "Hurlbut, Jesse Lyman: 8\n",
      "Hoover, Thomas: 9\n",
      "Herford, Oliver: 10\n",
      "Morris, Charles: 16\n",
      "Carlyle, Thomas: 37\n",
      "Rolt-Wheeler, Francis: 9\n",
      "Ingersoll, Robert Green: 31\n",
      "Spence, Lewis: 8\n",
      "MacGregor, Mary Esther Miller: 10\n",
      "Gaboriau, Emile: 13\n",
      "Read, Opie Percival: 9\n",
      "Quiller-Couch, Mabel: 9\n",
      "Ballou, Maturin Murray: 17\n",
      "Malot, Hector: 8\n",
      "Virgil: 7\n",
      "Burroughs, John: 22\n",
      "Hay, Ian: 11\n",
      "Parkerson, James: 9\n",
      "Lucas, E. V. (Edward Verrall): 12\n",
      "Mathews, Joanna H. (Joanna Hooe): 12\n",
      "Merwin, Samuel: 7\n",
      "Browning, Elizabeth Barrett: 8\n",
      "Noyes, Alfred: 8\n",
      "Laut, Agnes C.: 12\n",
      "Brazil, Angela: 26\n",
      "Burgess, Thornton W. (Thornton Waldo): 38\n",
      "Lowell, James Russell: 10\n",
      "Sienkiewicz, Henryk: 17\n",
      "Smith, Mabell S. C. (Mabell Shippie Clarke): 7\n",
      "Gissing, George: 21\n",
      "Watson, John F. (John Fanning): 11\n",
      "Speed, Nell: 16\n",
      "Haeckel, Ernst: 12\n",
      "Auerbach, Berthold: 10\n",
      "Le Queux, William: 67\n",
      "Bird, Isabella L. (Isabella Lucy): 8\n",
      "Westerman, Percy F. (Percy Francis): 18\n",
      "Sheckley, Robert: 20\n",
      "Oxley, J. Macdonald (James Macdonald): 8\n",
      "Lang, Andrew: 53\n",
      "Hocking, Joseph: 12\n",
      "Wordsworth, William: 10\n",
      "Madison, Lucy Foster: 8\n",
      "Ebers, Georg: 163\n",
      "Stockton, Frank Richard: 32\n",
      "Alcott, Louisa May: 38\n",
      "Lincoln, Abraham: 20\n",
      "Milne, A. A. (Alan Alexander): 12\n",
      "Thurston, Edgar: 8\n",
      "Macaulay, Thomas Babington Macaulay, Baron: 15\n",
      "Whyte-Melville, G. J. (George John): 9\n",
      "Vaknin, Samuel: 13\n",
      "Burnett, Frances Hodgson: 39\n",
      "MÃ¼hlbach, L. (Luise): 19\n",
      "Fleming, May Agnes: 11\n",
      "Godwin, William: 8\n",
      "De Vet, Charles V. (Charles Vincent): 8\n",
      "Morrow, HonorÃ©: 7\n",
      "Fabre, Jean-Henri: 8\n",
      "Murray, David Christie: 14\n",
      "Collins, Wilkie: 36\n",
      "LagerlÃ¶f, Selma: 8\n",
      "King, Basil: 10\n",
      "Boswell, James: 8\n",
      "Wilson, Harry Leon: 13\n",
      "CoppÃ©e, FranÃ§ois: 8\n",
      "Ray, Anna Chapin: 7\n",
      "Shaler, Robert: 10\n",
      "United States. Central Intelligence Agency: 21\n",
      "Buck, Charles Neville: 10\n",
      "Stacpoole, H. De Vere (Henry De Vere): 8\n",
      "Sheridan, Philip Henry: 9\n",
      "Holmes, Mary Jane: 21\n",
      "Santayana, George: 7\n",
      "Besant, Annie: 17\n",
      "Verne, Jules: 43\n",
      "BahÃ¡'u'llÃ¡h: 11\n",
      "Sharp, Dallas Lore: 10\n",
      "Hall, E. Raymond (Eugene Raymond): 16\n",
      "White, Stewart Edward: 21\n",
      "Ibsen, Henrik: 17\n",
      "Lewis, Alfred Henry: 12\n",
      "Stephens, Robert Neilson: 8\n",
      "Jonson, Ben: 9\n",
      "Sinclair, Upton: 25\n",
      "Evans, Augusta J. (Augusta Jane): 8\n",
      "Blasco IbÃ¡Ã±ez, Vicente: 14\n",
      "Castlemon, Harry: 20\n",
      "Hume, Fergus: 24\n",
      "Vandercook, Margaret: 21\n",
      "Hudson, W. H. (William Henry): 15\n",
      "Baker, Samuel White, Sir: 8\n",
      "Hope, Laura Lee: 65\n",
      "Tennyson, Alfred Tennyson, Baron: 11\n",
      "McElroy, John: 15\n",
      "Glasgow, Ellen Anderson Gholson: 11\n",
      "Brooks, Amy: 8\n",
      "Motley, John Lothrop: 103\n",
      "Carey, Rosa Nouchette: 10\n",
      "Thorne, Guy: 15\n",
      "Oxenham, John: 7\n",
      "Johnson, Samuel: 20\n",
      "Burnham, Clara Louise: 8\n",
      "Wilson, Ann: 12\n",
      "Fletcher, J. S. (Joseph Smith): 16\n",
      "Russell, William Clark: 12\n",
      "Stoker, Bram: 8\n",
      "Disraeli, Benjamin, Earl of Beaconsfield: 16\n",
      "King, Charles: 26\n",
      "Piper, H. Beam: 30\n",
      "Couperus, Louis: 13\n",
      "Henry, O.: 15\n",
      "Plutarch: 8\n",
      "Mansfield, M. F. (Milburg Francisco): 11\n",
      "Ewing, Juliana Horatia Gatty: 19\n",
      "Smith, Evelyn E.: 14\n",
      "Swift, Jonathan: 14\n",
      "Williams, Robert Moore: 9\n",
      "Walsh, James J. (James Joseph): 11\n",
      "Parker, Gilbert: 134\n",
      "Bowen, Robert Sidney: 14\n",
      "Heyse, Paul: 10\n",
      "Atherton, Gertrude Franklin Horn: 19\n",
      "Arthur, T. S. (Timothy Shay): 32\n",
      "Bierce, Ambrose: 19\n",
      "Ade, George: 8\n",
      "Meynell, Alice: 11\n",
      "Munroe, Kirk: 12\n",
      "Bensusan, S. L. (Samuel Levy): 12\n",
      "Foote, G. W. (George William): 9\n",
      "Cable, George Washington: 14\n",
      "Churchill, Winston: 70\n",
      "Stratemeyer, Edward: 67\n",
      "Smith, Francis Hopkinson: 25\n",
      "Hakluyt, Richard: 9\n",
      "Dostoyevsky, Fyodor: 9\n",
      "Taine, Hippolyte: 7\n",
      "Dickens, Charles: 48\n",
      "Baldwin, James: 9\n",
      "Marlowe, Stephen: 17\n",
      "Wilcox, Ella Wheeler: 9\n",
      "MÃ¼ller, F. Max (Friedrich Max): 9\n",
      "Crockett, S. R. (Samuel Rutherford): 18\n",
      "Aycock, Roger D.: 10\n",
      "Goethe, Johann Wolfgang von: 11\n",
      "McCarthy, Justin: 8\n",
      "Parmele, Mary Platt: 8\n",
      "Maupassant, Guy de: 31\n",
      "Melville, Herman: 18\n",
      "Fitzhugh, Percy Keese: 22\n",
      "Spielhagen, Friedrich: 9\n",
      "Janvier, Thomas A. (Thomas Allibone): 13\n",
      "Reade, Charles: 14\n",
      "Nourse, Alan Edward: 23\n",
      "Plato: 28\n",
      "Field, Eugene: 15\n",
      "Anderson, Sydney: 8\n",
      "Stephens, James: 8\n",
      "Barrie, J. M. (James Matthew): 30\n",
      "Green, John Richard: 9\n",
      "Smith, George O. (George Oliver): 9\n",
      "Webster, Noah: 12\n",
      "Fiske, John: 16\n",
      "Hough, Emerson: 23\n",
      "Sylvester, Charles Herbert: 7\n",
      "Yeats, W. B. (William Butler): 28\n",
      "Lincoln, Joseph Crosby: 19\n",
      "Ford, Ford Madox: 8\n",
      "Serviss, Garrett Putman: 9\n",
      "Burgess, Gelett: 9\n",
      "Byron, May Clarissa Gillington: 8\n",
      "Xenophon: 17\n",
      "Le Feuvre, Amy: 9\n",
      "Stowe, Harriet Beecher: 19\n",
      "Shaara, Michael: 7\n",
      "Rathborne, St. George: 12\n",
      "Scott, Walter: 59\n",
      "McCutcheon, George Barr: 30\n",
      "Cholmondeley, Mary: 11\n",
      "Carroll, Lewis: 16\n",
      "Wiggin, Kate Douglas Smith: 32\n",
      "Service, Robert W. (Robert William): 8\n",
      "Webster, Frank V.: 19\n",
      "Wilson, Woodrow: 8\n",
      "Conrad, Joseph: 34\n",
      "Borrow, George: 35\n",
      "Euripides: 10\n",
      "Flaubert, Gustave: 12\n",
      "Harrison, Harry: 11\n",
      "Birmingham, George A.: 14\n",
      "Mitchell, S. Weir (Silas Weir): 11\n",
      "Tracy, Louis: 26\n",
      "Raymond, Evelyn: 17\n",
      "Garrett, Randall: 41\n",
      "Pemberton, Max: 10\n",
      "Chesterton, G. K. (Gilbert Keith): 41\n",
      "Zola, Ãmile: 35\n",
      "Thoreau, Henry David: 9\n",
      "Altsheler, Joseph A. (Joseph Alexander): 33\n",
      "Bacon, Josephine Daskam: 12\n",
      "Lear, Edward: 9\n",
      "Appleton, Victor: 31\n",
      "Lee, Vernon: 15\n",
      "Cather, Willa: 9\n",
      "Rohmer, Sax: 17\n",
      "Abbott, John S. C. (John Stevens Cabot): 21\n",
      "Gordon, S. D. (Samuel Dickey): 8\n",
      "Meade, L. T.: 52\n",
      "Du Hausset, Mme.: 9\n",
      "Roy, Lillian Elizabeth: 16\n",
      "James, Henry: 60\n",
      "Ruskin, John: 44\n",
      "Penrose, Margaret: 18\n",
      "Fenn, George Manville: 128\n",
      "Bangs, John Kendrick: 35\n",
      "Fanny, Aunt: 11\n",
      "Russell, George William: 7\n",
      "De Quincey, Thomas: 14\n",
      "BjÃ¸rnson, BjÃ¸rnstjerne: 16\n",
      "Franklin, Benjamin: 9\n",
      "Jacobs, W. W. (William Wymark): 110\n",
      "Brinton, Daniel G. (Daniel Garrison): 15\n",
      "Montgomery, L. M. (Lucy Maud): 17\n",
      "Montespan, FranÃ§oise-AthÃ©naÃ¯s de Rochechouart de Mortemart, marquise de: 9\n",
      "Catherwood, Mary Hartwell: 17\n",
      "Eggleston, George Cary: 14\n",
      "Hale, Edward Everett: 8\n",
      "Vaizey, George de Horne, Mrs.: 23\n",
      "Atkinson, William Walker: 19\n",
      "Stoddard, William Osborn: 11\n",
      "Old Sleuth: 7\n",
      "Beerbohm, Max, Sir: 10\n",
      "Brand, Max: 16\n",
      "Froude, James Anthony: 10\n",
      "Cummings, Ray: 8\n",
      "Aimard, Gustave: 28\n",
      "Andersen, H. C. (Hans Christian): 14\n",
      "Beers, Henry A. (Henry Augustin): 8\n",
      "Hayes, Clair W. (Clair Wallace): 18\n",
      "Voltaire: 18\n",
      "Clarkson, Thomas: 8\n",
      "Le Gallienne, Richard: 17\n",
      "Milton, John: 10\n",
      "Parkman, Francis: 11\n",
      "Kipling, Rudyard: 51\n",
      "Webster, Jean: 10\n",
      "Onions, Oliver: 10\n",
      "Walpole, Horace: 9\n",
      "Bacheller, Irving: 14\n",
      "Strang, Herbert: 32\n",
      "Gautier, ThÃ©ophile: 8\n",
      "Spinoza, Benedictus de: 12\n",
      "London, Jack: 46\n",
      "Goodrich, Samuel G. (Samuel Griswold): 8\n",
      "Pyle, Howard: 14\n",
      "Stringer, Arthur: 9\n",
      "Austen, Jane: 13\n",
      "Dryden, John: 11\n",
      "Erckmann-Chatrian: 8\n",
      "Weinbaum, Stanley Grauman: 7\n",
      "Holmes, Oliver Wendell: 36\n",
      "Robertson, Margaret M. (Margaret Murray): 11\n",
      "Graham, Harry: 10\n",
      "Reed, Myrtle: 12\n",
      "Brown, Paul Cameron: 10\n",
      "Sharkey, Jack: 9\n",
      "Moore, Thomas: 10\n",
      "Parrish, Randall: 15\n",
      "Johnston, Mary: 11\n",
      "Reid, Mayne: 52\n",
      "Aldrich, Thomas Bailey: 19\n",
      "Rockwell, Carey: 7\n",
      "Tagore, Rabindranath: 17\n",
      "Crabbe, George: 8\n",
      "Wallace, Alfred Russel: 7\n",
      "Brandeis, Madeline: 9\n",
      "Morris, William: 20\n",
      "Marryat, Frederick: 44\n",
      "Standish, Burt L.: 23\n",
      "Marshall, Archibald: 10\n",
      "Leiber, Fritz: 19\n",
      "Ballantyne, R. M. (Robert Michael): 97\n",
      "Everett-Green, Evelyn: 14\n",
      "Weymouth, Richard Francis: 28\n",
      "`Abdu'l-BahÃ¡: 15\n",
      "Turgenev, Ivan Sergeevich: 20\n",
      "Samachson, Joseph: 11\n",
      "Mills, Enos A.: 9\n",
      "Blackwood, Algernon: 19\n",
      "Del Rey, Lester: 11\n",
      "Riis, Jacob A. (Jacob August): 11\n",
      "Allen, James Lane: 12\n",
      "Kingsley, Charles: 33\n",
      "Leblanc, Maurice: 16\n",
      "Jones, Raymond F.: 8\n",
      "Galsworthy, John: 50\n",
      "Sidney, Margaret: 9\n",
      "Creswicke, Louis: 8\n",
      "Potter, Beatrix: 23\n",
      "Cervantes Saavedra, Miguel de: 48\n",
      "Cabell, James Branch: 13\n",
      "Cobb, Irvin S. (Irvin Shrewsbury): 24\n",
      "Hughes, Rupert: 12\n",
      "More, Hannah: 8\n",
      "Nesbit, E. (Edith): 29\n",
      "Perkins, Lucy Fitch: 13\n",
      "Browning, Robert: 10\n",
      "Erasmus, Desiderius: 10\n",
      "Hornung, E. W. (Ernest William): 25\n",
      "Jewett, Sarah Orne: 12\n",
      "Bellamy, Edward: 21\n",
      "Paine, Albert Bigelow: 29\n",
      "Connor, Ralph: 14\n",
      "Rousseau, Jean-Jacques: 19\n",
      "Seton, Ernest Thompson: 15\n",
      "Alger, Horatio, Jr.: 70\n",
      "Matthews, Stanley R.: 10\n",
      "Grey, Zane: 23\n",
      "MacGrath, Harold: 21\n",
      "Le Fanu, Joseph Sheridan: 31\n",
      "Gregory, Lady: 8\n",
      "Glyn, Elinor: 16\n",
      "Skinner, Charles M. (Charles Montgomery): 11\n",
      "Perrault, Charles: 8\n",
      "Hewlett, Maurice: 14\n",
      "Holmes, William Henry: 9\n",
      "United States. Warren Commission: 12\n",
      "Norton, Andre: 14\n",
      "Saint-Simon, Louis de Rouvroy, duc de: 17\n",
      "Maeterlinck, Maurice: 13\n",
      "Norris, Frank: 10\n",
      "Baker, Willard F.: 8\n",
      "Daviess, Maria Thompson: 12\n",
      "Freeman, Mary Eleanor Wilkins: 24\n",
      "Bradlaugh, Charles: 9\n",
      "Yonge, Charlotte M. (Charlotte Mary): 49\n",
      "Dante Alighieri: 36\n",
      "Brown, Charles Brockden: 8\n",
      "Snell, Roy J. (Roy Judson): 38\n",
      "Adams, Andy: 10\n",
      "Schmitz, James H.: 11\n",
      "Goodwin, Harold L. (Harold Leland): 13\n",
      "Methuen & Co.: 7\n",
      "Stevenson, Robert Louis: 64\n",
      "Stevenson, Burton Egbert: 15\n",
      "Trollope, Anthony: 57\n",
      "Strindberg, August: 22\n",
      "Riley, James Whitcomb: 20\n",
      "Taylor, Bayard: 8\n",
      "Carter, Herbert, active 1909-1917: 11\n",
      "Mason, A. E. W. (Alfred Edward Woodley): 20\n",
      "Munro, Neil: 7\n",
      "Eliot, George: 18\n",
      "Logan, John Alexander: 8\n",
      "Pansy: 11\n",
      "Phillips, David Graham: 13\n",
      "Tapper, Thomas: 13\n",
      "Ouida: 14\n",
      "MacKenzie, Compton: 12\n",
      "Garis, Howard Roger: 29\n",
      "Murray, Gilbert: 8\n",
      "Stephen, Leslie: 11\n",
      "Hulbert, Archer Butler: 16\n",
      "Werner, E.: 18\n",
      "Du Bois, W. E. B. (William Edward Burghardt): 8\n",
      "Burney, Fanny: 13\n",
      "Richardson, Major (John): 10\n",
      "Blanchard, Amy Ella: 12\n",
      "Rice, Cale Young: 10\n",
      "Corelli, Marie: 14\n",
      "Eddy, Mary Baker: 12\n",
      "Brereton, F. S. (Frederick Sadleir): 18\n",
      "Hamilton, Anthony, Count: 9\n",
      "Haggard, H. Rider (Henry Rider): 54\n",
      "Duchess: 16\n",
      "Wairy, Louis Constant: 13\n",
      "Hill, Grace Livingston: 14\n",
      "Sherman, William T. (William Tecumseh): 7\n",
      "Hichens, Robert: 28\n",
      "Janifer, Laurence M.: 13\n",
      "Ontario. Ministry of Education: 9\n",
      "Pepys, Samuel: 87\n",
      "Cody, H. A. (Hiram Alfred): 12\n",
      "JÃ³kai, MÃ³r: 28\n",
      "Cawein, Madison Julius: 16\n",
      "Mackintosh, Charles Henry: 9\n",
      "Byron, George Gordon Byron, Baron: 9\n",
      "Moore, George Augustus: 14\n",
      "Seltzer, Charles Alden: 10\n",
      "McGuinn, Roger: 30\n",
      "Goldsmith, Lewis: 9\n",
      "Farrar, F. W. (Frederic William): 8\n",
      "Duffield, J. W.: 9\n",
      "Neville, Kris: 9\n",
      "Braddon, M. E. (Mary Elizabeth): 28\n",
      "Balzac, HonorÃ© de: 120\n",
      "Shakespeare, William: 167\n",
      "Emerson, Alice B.: 23\n",
      "Burke, Edmund: 15\n",
      "Saltus, Edgar: 13\n",
      "Twain, Mark: 148\n",
      "Frazer, James George: 15\n",
      "Grahame, Kenneth: 9\n",
      "Swedenborg, Emanuel: 7\n",
      "Buffon, Georges Louis Leclerc, comte de: 10\n",
      "Wallace, F. L. (Floyd L.): 13\n",
      "Warner, Susan: 22\n",
      "Wells, H. G. (Herbert George): 52\n",
      "Deland, Margaret Wade Campbell: 9\n",
      "United States. Work Projects Administration: 34\n",
      "Day, Holman: 9\n",
      "Dowling, Richard: 15\n",
      "Curtis, George William: 9\n",
      "Benson, Robert Hugh: 10\n",
      "Shea, Robert: 7\n",
      "Douglas, Amanda M.: 19\n",
      "Bennett, Arnold: 39\n",
      "Benson, Arthur Christopher: 18\n",
      "Leslie, Madeline: 20\n",
      "Belloc, Hilaire: 20\n",
      "Harmon, Jim: 13\n",
      "Grant, James, archaeologist: 12\n",
      "Peard, Frances Mary: 9\n",
      "White, Fred M. (Fred Merrick): 8\n",
      "Shelley, Percy Bysshe: 10\n",
      "Lebert, Marie: 15\n",
      "Ward, Humphry, Mrs.: 34\n",
      "Abbott, Jacob: 49\n",
      "Hill, Grace Brooks: 11\n",
      "O'Rell, Max: 7\n",
      "Paine, Thomas: 7\n",
      "Young, F. E. Mills (Florence Ethel Mills): 7\n",
      "Romanes, George John: 9\n",
      "Wharton, Edith: 31\n",
      "Barr, Robert: 14\n",
      "Lever, Charles James: 51\n",
      "Scully, W. C. (William Charles): 7\n",
      "Whistler, Charles W. (Charles Watts): 8\n",
      "Merriman, Henry Seton: 13\n",
      "Ralphson, G. Harvey (George Harvey): 14\n",
      "Huxley, Thomas Henry: 47\n",
      "Lamb, Charles: 13\n",
      "Otis, James: 45\n",
      "Phillpotts, Eden: 11\n",
      "Chambers, Robert W. (Robert William): 42\n",
      "Lord, John: 19\n",
      "Chadwick, Lester: 16\n",
      "Smith, J. Jay (John Jay): 13\n",
      "Train, Arthur Cheney: 9\n",
      "Wodehouse, P. G. (Pelham Grenville): 38\n",
      "Leinster, Murray: 33\n",
      "Crane, Walter: 13\n",
      "Bone, Jesse F. (Jesse Franklin): 12\n",
      "McGuffey, William Holmes: 8\n",
      "Zangwill, Israel: 12\n",
      "Tupper, Martin Farquhar: 7\n",
      "Adams, Samuel Hopkins: 13\n",
      "James, George Wharton: 8\n",
      "Dick, Philip K.: 13\n",
      "Phelps, Elizabeth Stuart: 11\n",
      "Fisher, Dorothy Canfield: 8\n",
      "Brown, Alice: 8\n",
      "Kock, Paul de: 12\n",
      "Aesop: 9\n",
      "Orczy, Emmuska Orczy, Baroness: 19\n",
      "Rawlinson, George: 9\n",
      "Dunsany, Lord: 16\n",
      "Craik, Dinah Maria Mulock: 12\n",
      "Roberts, Charles G. D., Sir: 20\n",
      "Whittier, John Greenleaf: 44\n",
      "Roe, Edward Payson: 19\n",
      "Von Arnim, Elizabeth: 12\n",
      "Holbach, Paul Henri Thiry, baron d': 8\n",
      "Harris, Frank: 10\n",
      "Baum, L. Frank (Lyman Frank): 63\n",
      "Follen, Eliza Lee Cabot: 10\n",
      "Warner, Anne: 10\n",
      "Marks, Winston K.: 12\n",
      "Wagner, Richard: 8\n",
      "Masefield, John: 13\n",
      "Van Dyke, Henry: 32\n",
      "Hawthorne, Julian: 11\n",
      "Emerson, Ralph Waldo: 12\n",
      "Spooner, Lysander: 7\n",
      "Reynolds, Mack: 22\n",
      "Crawford, F. Marion (Francis Marion): 41\n",
      "Edgeworth, Maria: 18\n",
      "Stewart, Jane L.: 8\n",
      "Weyman, Stanley John: 28\n",
      "Hearn, Lafcadio: 12\n",
      "Sabatini, Rafael: 17\n",
      "Bassett, Sara Ware: 16\n",
      "Schiller, Friedrich: 35\n",
      "De Mille, James: 12\n",
      "Ritchie, J. Ewing (James Ewing): 10\n",
      "Davis, Richard Harding: 48\n",
      "Bower, B. M.: 29\n",
      "Hardy, Thomas: 21\n",
      "Petronius Arbiter: 8\n",
      "Mundy, Talbot: 13\n",
      "Murfree, Mary Noailles: 25\n",
      "Jerome, Jerome K. (Jerome Klapka): 26\n",
      "Oppenheim, E. Phillips (Edward Phillips): 55\n",
      "Tarkington, Booth: 19\n",
      "Vasari, Giorgio: 11\n",
      "Ford, Sewell: 12\n",
      "Lawrence, D. H. (David Herbert): 18\n",
      "Bindloss, Harold: 44\n",
      "Longfellow, Henry Wadsworth: 11\n",
      "Warner, Charles Dudley: 45\n",
      "Kyne, Peter B. (Peter Bernard): 9\n",
      "De la Mare, Walter: 9\n",
      "Mitford, Mary Russell: 13\n",
      "Quiller-Couch, Arthur: 39\n",
      "Harte, Bret: 59\n",
      "Chaucer, Geoffrey: 9\n",
      "Child, Lydia Maria: 8\n",
      "Young, Filson: 12\n",
      "Home, Gordon: 16\n",
      "Reed, Helen Leah: 9\n",
      "Hugo, Victor: 9\n",
      "Mill, John Stuart: 14\n",
      "Chekhov, Anton Pavlovich: 22\n",
      "Jefferson, Thomas: 11\n",
      "Holt, Emily Sarah: 22\n",
      "Harris, Joel Chandler: 12\n",
      "Ellis, Edward Sylvester: 48\n",
      "Dewey, John: 13\n",
      "Wright, Harold Bell: 10\n",
      "Dumas, Alexandre: 49\n",
      "Chesterfield, Philip Dormer Stanhope, Earl of: 13\n",
      "Russell, Bertrand: 8\n",
      "Hutcheson, John C. (John Conroy): 17\n",
      "Howells, William Dean: 97\n",
      "La Fontaine, Jean de: 31\n",
      "Talmage, James E. (James Edward): 7\n",
      "Robins, Elizabeth: 7\n",
      "Curtis, William: 10\n",
      "Hubbard, Elbert: 19\n",
      "Kingston, William Henry Giles: 132\n",
      "Mangasarian, M. M. (Mangasar Mugurditch): 12\n",
      "Green, Anna Katharine: 36\n",
      "Beaumont, Francis: 18\n",
      "Fyfe, H. B. (Horace Bowne): 16\n",
      "Morley, John: 30\n",
      "Howard, Robert E. (Robert Ervin): 12\n",
      "Bailey, Temple: 8\n",
      "Garland, Hamlin: 22\n",
      "Walton, Amy: 10\n",
      "Defoe, Daniel: 42\n",
      "Wake, William: 10\n",
      "Holland, Rupert Sargent: 9\n",
      "Brady, Cyrus Townsend: 10\n",
      "Marlowe, Christopher: 13\n",
      "Suetonius: 15\n",
      "Grinnell, George Bird: 10\n",
      "Kjelgaard, Jim: 11\n",
      "Packard, Frank L. (Frank Lucius): 7\n",
      "Library of Congress. Copyright Office: 9\n",
      "Spyri, Johanna: 16\n",
      "Southworth, Emma Dorothy Eliza Nevitte: 13\n",
      "Abbott, Eleanor Hallowell: 10\n",
      "Guizot, FranÃ§ois: 8\n",
      "Barr, Amelia E.: 25\n",
      "Doctorow, Cory: 10\n",
      "Machen, Arthur: 10\n",
      "Reed, Talbot Baines: 15\n",
      "James, G. P. R. (George Payne Rainsford): 17\n",
      "Brame, Charlotte M.: 11\n",
      "Ainsworth, William Harrison: 13\n",
      "Cory, David: 14\n",
      "Ellis, Havelock: 10\n",
      "Smith, E. E. (Edward Elmer): 10\n",
      "Allen, Grant: 22\n",
      "Slesar, Henry: 7\n",
      "Campan, Mme. (Jeanne-Louise-Henriette): 9\n",
      "Grant, Ulysses S. (Ulysses Simpson): 12\n",
      "Saintsbury, George: 11\n",
      "Allen, Quincy: 8\n",
      "Maclaren, Ian: 14\n",
      "Walpole, Hugh: 11\n",
      "Tolstoy, Leo, graf: 31\n",
      "Eggleston, Edward: 11\n",
      "Raine, William MacLeod: 22\n",
      "Sumner, Charles: 7\n",
      "Austin, Mary Hunter: 8\n",
      "OrlÃ©ans, Charlotte-Elisabeth, duchesse d': 7\n",
      "Collingwood, Harry: 34\n",
      "Rolland, Romain: 7\n",
      "Coleridge, Samuel Taylor: 14\n",
      "Jefferies, Richard: 19\n",
      "Hancock, H. Irving (Harrie Irving): 37\n",
      "Sinclair, May: 20\n",
      "Gibbs, George: 10\n",
      "Holinshed, Raphael: 20\n",
      "Williams, Henry Smith: 7\n",
      "Jackson, Helen Hunt: 13\n",
      "Morley, Christopher: 12\n",
      "Huneker, James: 8\n",
      "Richardson, Samuel: 13\n",
      "Laumer, Keith: 11\n",
      "Dixon, Thomas: 10\n",
      "James, William: 9\n",
      "Butler, Samuel: 11\n",
      "Butterworth, Hezekiah: 8\n",
      "Anderson, Poul: 8\n",
      "Blackmore, R. D. (Richard Doddridge): 18\n",
      "Wallace, Dillon: 11\n",
      "Terhune, Albert Payson: 7\n"
     ]
    }
   ],
   "source": [
    "print('The number of authors mentioned in the Gutenberg corpus are:',format(len(authors)))\n",
    "for author in authors:\n",
    "    print(\"{0}: {1}\".format(author,len(authors[author])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialising our problem with parsing the novel by James De Mille for analyzing feature sets of characters. The name of the selected novel is The Cryptogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among the Brigands\n",
      "Cord and Creese\n",
      "A Castle in Spain: A Novel\n",
      "Lost in the Fog\n",
      "The Lady of the Ice: A Novel\n",
      "The Cryptogram: A Novel\n",
      "A Strange Manuscript Found in a Copper Cylinder\n",
      "The American Baron: A Novel\n",
      "The Lily and the Cross: A Tale of Acadia\n",
      "The Living Link: A Novel\n",
      "The Martyr of the Catacombs\n",
      "A Tale of Ancient Rome\n",
      "The Dodge Club; Or, Italy in MDCCCLIX\n"
     ]
    }
   ],
   "source": [
    "os.chdir('C://Users//cmm//Desktop//NLP//resources')\n",
    "from sussex_nltk.corpus_readers import AmazonReviewCorpusReader\n",
    "from GutenbergCorpus import GutenbergCorpusReader as gcr\n",
    "reader = gcr.GutenbergCorpusReader()\n",
    "reader = gcr.GutenbergCorpusReader(\"C://Users//cmm//Desktop//NLP//resources//data//gutenberg_eng\") \n",
    "\n",
    "authors = reader.get_authors()\n",
    "tot = 0\n",
    "for author in authors:\n",
    "    tot += len(authors[author])\n",
    "\n",
    "works = reader.get_authors_works('De Mille, James')\n",
    "for work in works:\n",
    "    print(work[\"title\"])\n",
    "parsed_novel = nlp(works[7][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The code returns the feature sets for characters extracted from the novel. The code has added functionality to remove most common occuring verbs in the novel. Also, addition of relations 'nsubj' and 'dobj' are added.\n",
    "\n",
    "\n",
    "#### Defining our helper functions:\n",
    "- get_entities_in(parsed_novel,entity_type): inputs parsed novel and entity type to be extracted, returns an array with extracted user defined type entity names\n",
    "\n",
    "- get_main_characters(parsed_novel,num_characters)\n",
    "- get_main_characters(parsed_novel,num_characters):\n",
    "- get_interesting_contexts(novels,rels,num_characters,verb_stop)\n",
    "- get_pos_in(parsed_novel,pos_type,remove_pos_numb): Extracts all common verbs from the novel and returns a list of all common verbs\n",
    "\n",
    "remove_pos_numb is the argument that filters common verbs. The number signifies the first n numbers to be removed from the most common verbs. Interseting contexts and characteristics the user has are to be determined by removing most common verbs.\n",
    "\n",
    "The main function 'get interesting contexts' runs on the parsed novel, entities that are in main characters identified by get_main_characters are identified. Verbs and relations associated with these entities are extracted. \n",
    "Stop verbs are removed and a Counter of verbs is returned as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baron</th>\n",
       "      <th>dacres</th>\n",
       "      <th>ethel</th>\n",
       "      <th>girasole</th>\n",
       "      <th>kitty</th>\n",
       "      <th>lady dalrymple</th>\n",
       "      <th>minnie</th>\n",
       "      <th>willoughby</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>add</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bend</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bewilder</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bow</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brush</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clasp</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clinch</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confide</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confront</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continue</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>converse</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dart</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disappear</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discomfit</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discourse</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drift</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elevate</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embrace</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exchange</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exclaim</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experience</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frown</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gone--\"now</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grasp</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>growl</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hand</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heave</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kiss</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linger</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refresh</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refuse</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reiterate</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relapse</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remind</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reply</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rescue</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retort</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scout</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shrink</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shudder</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigh</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slacken</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smile</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snatch</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sob</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spring</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stammer</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>steal</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stipulate</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sympathize</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toss</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tramp</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>urge</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utter</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wander</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whisper</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>withdraw</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worry</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows Ã 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           baron dacres ethel girasole kitty lady dalrymple minnie willoughby\n",
       "add                         1                                                \n",
       "bend                        3                                                \n",
       "bewilder       1                                                             \n",
       "bow                                                       2                  \n",
       "brush          2                                                             \n",
       "clasp                                                                       1\n",
       "clinch         1                                                             \n",
       "confide        1                                                             \n",
       "confront                                                         1           \n",
       "continue       1      3                                          1          2\n",
       "converse                             1                                       \n",
       "dart                        1                                                \n",
       "disappear                            1                                       \n",
       "discomfit                                                                   1\n",
       "discourse      1                                                             \n",
       "drift                 1                                                      \n",
       "elevate                                                   1                 1\n",
       "embrace                                                                     1\n",
       "exchange                                                  1                 1\n",
       "exclaim               1     1              1                     1          6\n",
       "experience                  1                                                \n",
       "frown                                                            1           \n",
       "gone--\"now                           1                                       \n",
       "grasp          1                                                            1\n",
       "growl                 2                                                      \n",
       "hand           1                                                             \n",
       "heave                                                            1           \n",
       "intercept                            1                                       \n",
       "kiss                        1                                                \n",
       "linger         1                                                             \n",
       "...          ...    ...   ...      ...   ...            ...    ...        ...\n",
       "refresh               1                                                      \n",
       "refuse                                                                      1\n",
       "reiterate                                                        1           \n",
       "relapse               1                                          2           \n",
       "remind                                                           1           \n",
       "reply                       1                                    1           \n",
       "rescue         1                                                             \n",
       "retort                                                           1           \n",
       "scout                       1                                                \n",
       "shrink                      1                                               1\n",
       "shudder                                                                     2\n",
       "sigh                                                             1          4\n",
       "slacken               1                                                      \n",
       "smile                                1                                      1\n",
       "snatch                                                                      1\n",
       "sob                                                              1           \n",
       "spring         1      2              1                                       \n",
       "stammer                                                          1           \n",
       "star                                                                        1\n",
       "steal                       2                                                \n",
       "stipulate                                                        1           \n",
       "sympathize                                                       1           \n",
       "toss                                                             1           \n",
       "tramp                 1                                                      \n",
       "urge                                                                        1\n",
       "utter                                                            1           \n",
       "wander         1                                                             \n",
       "whisper                                                                     1\n",
       "withdraw                    1                                                \n",
       "worry                       1                                                \n",
       "\n",
       "[73 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_entities_in(parsed_novel,entity_type): ## Get_entities_in returns entity in a novel given the type of entity \n",
    "    \n",
    "    return [ent.text.strip().lower() for ent in parsed_novel.ents \n",
    "            if ent.label_ == entity_type and ent.text.strip()]\n",
    "\n",
    "def get_pos_in(parsed_novel,pos_type,remove_pos_numb):   \n",
    "    \n",
    "## Get's the list of desired pos tag in passed tag and filters top n common entries\n",
    "\n",
    "    verbs = [token.text for token in parsed_novel if  token.pos_ == pos_type]\n",
    "    verbs = [verb.lower() for verb in verbs]\n",
    "    common_verbs=[]\n",
    "    for row in Counter(verbs).most_common()[:remove_pos_numb]:\n",
    "        common_verbs.append(row[0])\n",
    "    return common_verbs\n",
    "        \n",
    "def get_main_characters(parsed_novel,num_characters): \n",
    "    \n",
    "    # Function returns the most commonly occuring characters in a parsed novel\n",
    "    \n",
    "    C=(Counter(get_entities_in(parsed_novel,\"PERSON\")).most_common()[0:num_characters])\n",
    "    main_characters=[]\n",
    "    for row in C:\n",
    "        main_characters.append(row[0])\n",
    "    return Counter(main_characters)\n",
    "\n",
    "def get_interesting_contexts(novels,rels,num_characters,verb_stop):\n",
    "    \n",
    "    def of_interest(ent,rels,main_characters):\n",
    "        return (ent.text.strip().lower() in main_characters \n",
    "                and ent.label_ == 'PERSON' \n",
    "                and ent.root.head.pos_ == 'VERB'\n",
    "                and ent.root.dep_ in rels)  \n",
    "\n",
    "    contexts = defaultdict(Counter)    \n",
    "    for parsed_novel in novels:\n",
    "        main_characters = get_main_characters(parsed_novel,num_characters)\n",
    "        stop_verbs=get_pos_in(parsed_novel,'VERB',verb_stop)\n",
    "        for ent in parsed_novel.ents:\n",
    "            if of_interest(ent,rels,main_characters):\n",
    "                if ent.root.head.lemma_ not in stop_verbs:\n",
    "                    contexts[ent.text.strip().lower()][ent.root.head.lemma_] += 1\n",
    "    return contexts\n",
    "                \n",
    "\n",
    "novels = {parsed_novel}  ## Parsed novel\n",
    "number_of_characters_per_text = 8 ## Threshold for the number of characters you want contexts for\n",
    "target_rels = {'nsubj'} # Relation: Can treat entity as a subject. For object relations enter 'dobj'\n",
    "target_contexts = get_interesting_contexts(novels,target_rels,number_of_characters_per_text,1500)\n",
    "display(pd.DataFrame.from_dict(target_contexts).applymap(lambda x: '' if math.isnan(x) else x)) #Display result df\n",
    "# C=(Counter(get_entities_in(parsed_novel,\"VERB\")).most_common())\n",
    "# get_pos_in(parsed_novel,'VERB',60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This returns a dataframe with 73 action verbs that a character has performed in the novel.\n",
    "\n",
    "- By going through the list words it is easy to find the actions and notions a character is portrayed in.\n",
    "\n",
    "- The general tone of the novel with words appearing such as steal, stammer , sob, cry, kiss, bow, clasp etc.\n",
    "\n",
    "- Words appearing in the novel for certain characters may suggest the character traits identyfying the light in which the characters are portrayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since we are interested in quantifying the extent to which authors exhibit gender-based distinctions in the way they in the way that they portray their main characters, it would be useful to base this not only on the contexts of places where a character is mentioned by name, but also when a character is mentioned with a pronoun. The pronouns \"he\", \"she\", \"his\" and \"her\" indicate the gender of the person being referred to, so provide a reliable source of additional data.\n",
    "\n",
    "#### The following code cell shows how these pronouns can be extracted from a text using the `noun_chunks` property of a parsed document. Noun chunks are \"base noun phrases\" â flat phrases that have a noun as their head. You can think of noun chunks as a noun plus the words describing the noun â for example, \"the lavish green grass\" or \"the worldâs largest tech fund\". \n",
    "\n",
    "\n",
    "#### Extracting features from pronouns in the parsed_novel, there were 95 of these features found, after removing commonly occuring verbs. The function gendered_pronoun takes in an argument as the noun phrase and returns the noun phrases that have pronouns ;he, she, is and her'. These pronoun phrases are then used to extract the associative word attached to the pronoun. Common verbs occuring in the text are removed by the use of the previously created get_pos_in function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 327 noun phrases found.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Verb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>her</td>\n",
       "      <td>unlike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>her</td>\n",
       "      <td>about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>she</td>\n",
       "      <td>pouted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>he</td>\n",
       "      <td>whipped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>her</td>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>her</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>she</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>he</td>\n",
       "      <td>signaled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>her</td>\n",
       "      <td>restore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>her</td>\n",
       "      <td>upon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>she</td>\n",
       "      <td>reclined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>he</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>her</td>\n",
       "      <td>over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>her</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>her</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>he</td>\n",
       "      <td>established</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>he</td>\n",
       "      <td>bit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>her</td>\n",
       "      <td>bold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>her</td>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>her</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>her</td>\n",
       "      <td>resuscitate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>her</td>\n",
       "      <td>upon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>her</td>\n",
       "      <td>describe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>her</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>her</td>\n",
       "      <td>dissuaded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>her</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>her</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>her</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>her</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>her</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>her</td>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>he</td>\n",
       "      <td>detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>he</td>\n",
       "      <td>bracing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>her</td>\n",
       "      <td>Save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>her</td>\n",
       "      <td>over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>he</td>\n",
       "      <td>nurtured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>he</td>\n",
       "      <td>Is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>her</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>her</td>\n",
       "      <td>assuring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>her</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>her</td>\n",
       "      <td>proselytize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>he</td>\n",
       "      <td>attributed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>her</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>her</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>he</td>\n",
       "      <td>bargained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>her</td>\n",
       "      <td>assisting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>he</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>he</td>\n",
       "      <td>claiming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>her</td>\n",
       "      <td>claiming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>her</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>her</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>he</td>\n",
       "      <td>proposed--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>he</td>\n",
       "      <td>remind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>she</td>\n",
       "      <td>loathed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>her</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>her</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>her</td>\n",
       "      <td>mine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>her</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>her</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>her</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>327 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pronoun         Verb\n",
       "0       her       unlike\n",
       "1       her        about\n",
       "2       she       pouted\n",
       "3        he      whipped\n",
       "4       her        after\n",
       "5       her           to\n",
       "6       she          not\n",
       "7        he     signaled\n",
       "8       her      restore\n",
       "9       her         upon\n",
       "10      she     reclined\n",
       "11       he           --\n",
       "12      her         over\n",
       "13      her           on\n",
       "14      her           of\n",
       "15       he  established\n",
       "16       he          bit\n",
       "17      her         bold\n",
       "18      her        after\n",
       "19      her          for\n",
       "20      her  resuscitate\n",
       "21      her         upon\n",
       "22      her     describe\n",
       "23      her           to\n",
       "24      her    dissuaded\n",
       "25      her           on\n",
       "26      her           to\n",
       "27      her         with\n",
       "28      her           in\n",
       "29      her           to\n",
       "..      ...          ...\n",
       "297     her        after\n",
       "298      he     detected\n",
       "299      he      bracing\n",
       "300     her         Save\n",
       "301     her         over\n",
       "302      he     nurtured\n",
       "303      he           Is\n",
       "304     her           to\n",
       "305     her     assuring\n",
       "306     her           at\n",
       "307     her  proselytize\n",
       "308      he   attributed\n",
       "309     her           at\n",
       "310     her           at\n",
       "311      he    bargained\n",
       "312     her    assisting\n",
       "313      he           by\n",
       "314      he     claiming\n",
       "315     her     claiming\n",
       "316     her         with\n",
       "317     her           on\n",
       "318      he   proposed--\n",
       "319      he       remind\n",
       "320     she      loathed\n",
       "321     her           of\n",
       "322     her           of\n",
       "323     her         mine\n",
       "324     her           to\n",
       "325     her         with\n",
       "326     her           at\n",
       "\n",
       "[327 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gendered_pronoun(np):\n",
    "    return np.text.strip() in [\"he\", \"she\", \"her\", \"his\"]\n",
    "stop_verbs=get_pos_in(parsed_novel,'VERB',1400)\n",
    "text = parsed_novel\n",
    "nounphrases = [[re.sub(\"\\s+\",\" \",np.text), np.root.head.text] for np in parsed_novel.noun_chunks if gendered_pronoun(np) and np.root.head.text not in stop_verbs]\n",
    "print(\"There were {} noun phrases found.\".format(len(nounphrases)))\n",
    "df=(pd.DataFrame(nounphrases,columns=['Pronoun','Verb']))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating feature sets\n",
    "\n",
    "Once you are satisifed with the feature sets that you are able to build for a character, you are ready to undertake your analysis of the way characters are being portrayed based on gender.\n",
    "\n",
    "- Select a set of novels\n",
    "- Parse each of the novels with spaCy (this might take a while)\n",
    "- Determine the settings of any parameters that are needed by the code you have written to produce the character feature sets, e.g.\n",
    " - the number characters to consider in each novel\n",
    " - the number of most common verbs to disregard\n",
    "- Run your code that builds feature sets for characters over all of the novels under consideration\n",
    "- Build two aggregated feature sets, one for all female characters and one for all male characters\n",
    "\n",
    "In the next cell, we look at how to measure the difference between these two aggregated feature sets and how to assess whether the different you find is significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring the similarity of two feature sets\n",
    "\n",
    "The code cell below shows how to compare the similarity of two feature sets. This is now explained.\n",
    "\n",
    "- We are given two feature sets: `A` and `B`.\n",
    "- Initially, each feature set is represented as a `Counter` which is a dictionary where the keys are the features and each feature (key) is mapped to a positive number which corresponds to the strength (weight) of that feature. \n",
    " - feature set `A` has features `'a', 'b' and 'c'` with weights `1, 2 and 3`, respectively.\n",
    " - feature set `B` has features `'b', 'c', 'd' and 'e'` with weights `3, 4, 5 and 6`, respectively.\n",
    "- Note that they share some, but not all of their features.\n",
    "- Our goal is to represent both feature sets as lists in such a way that each position in a lists is consistently used for a particular feature\n",
    "- For example, we could use a list with 5 positions, where the weight of feature `'a'` is held in the first position, the weight of feature `'b'` is held in the second position, and so on. \n",
    " - with this scheme the feature list for `A` would be the list: `[1,2,3,0,0]`, and the feature list for `B` would be `[0,3,4,5,6]`.\n",
    "- The function `counters_to_feature_lists` takes two feature sets each of which is a `Counter` and returns two lists, one for each of the inputs, where both lists use the same feature representation.\n",
    "- In the first line of the function, the counters are added together. This is done because the keys of resulting counter (which is named `combined`) can be used to produce consistent mappings of the counters to lists - see lines 2 and 3.\n",
    "- Once consistent list representations are produced for the two feature sets, we can use the `cosine_similarity` function from `sklearn` as as a measure of how similar the lists are, and therefore, how similar the feature sets are.\n",
    "- `cosine_similarity` returns a real number between 0 and 1, with 1 indicating that the inputs are identical, and 0 indicating that the two inputs are completely different.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collection of novels from two different authors:\n",
    "- **The Cromptons** by Mary J. Holmes\n",
    "- **The Red Room** by H.G Wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "works = reader.get_authors_works('Holmes, Mary Jane')\n",
    "parsed_novel1 = nlp(works[2][\"text\"])\n",
    "works = reader.get_authors_works('Wells, H. G. (Herbert George)')\n",
    "parsed_novel2 = nlp(works[10][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch feature sets of the 2 novels parsed of all the male characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angel</th>\n",
       "      <th>howard</th>\n",
       "      <th>jack</th>\n",
       "      <th>jake</th>\n",
       "      <th>peter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>act</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>add</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appear</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>approach</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>argue</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bow</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breathe</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cease</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clench</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cling</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>construct</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consult</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contend</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continue</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curse</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dance</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decide</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>define</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desiccate</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detect</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deter</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drive</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exclaim</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eye</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fail</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finish</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forestall</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gather</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grasp</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greet</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paint</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plan</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pretend</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>propose</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rebuke</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>redden</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rejoin</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relent</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resist</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respond</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retreat</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>return</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saunter</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shift</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shrug</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuffle</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smile</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star</th>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stick</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stoop</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suffer</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suggest</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treat</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>untie</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>urge</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usher</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warn</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whisper</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows Ã 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          angel howard jack jake peter\n",
       "act           1           1           \n",
       "add                  1                \n",
       "appear        2                       \n",
       "approach      1                       \n",
       "argue                1                \n",
       "bow           1      1                \n",
       "breathe       1                       \n",
       "cease         1                       \n",
       "clench                         1      \n",
       "cling                                1\n",
       "construct                      1      \n",
       "consult              1                \n",
       "contend              1                \n",
       "continue                  4    1      \n",
       "curse                          1      \n",
       "dance         1                       \n",
       "decide                               1\n",
       "define               1                \n",
       "desiccate            1                \n",
       "detect                    1           \n",
       "deter                1                \n",
       "drive         1                       \n",
       "exclaim              2    2    1     1\n",
       "eye           1                       \n",
       "fail          1                       \n",
       "finish        1                       \n",
       "forestall                 2           \n",
       "gather               1                \n",
       "grasp                          1      \n",
       "greet                     1           \n",
       "...         ...    ...  ...  ...   ...\n",
       "paint         1                       \n",
       "plan                      1           \n",
       "pretend                   1           \n",
       "propose                   2           \n",
       "question                       1      \n",
       "rebuke        1                       \n",
       "redden                    1           \n",
       "rejoin               3                \n",
       "relent        1                       \n",
       "resist                    1           \n",
       "respond              2                \n",
       "retreat       1                       \n",
       "return        1                       \n",
       "saunter       1                       \n",
       "shift         1                       \n",
       "shrug         3      1    1           \n",
       "shuffle       1                       \n",
       "smile         4                       \n",
       "spot                      1           \n",
       "star         11                       \n",
       "stick         1                       \n",
       "stoop                     1           \n",
       "suffer                         1      \n",
       "suggest              3    4          1\n",
       "treat         1                       \n",
       "untie                     1           \n",
       "urge                      1           \n",
       "usher                          1      \n",
       "warn                           1      \n",
       "whisper       1                       \n",
       "\n",
       "[74 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_interesting_contexts_gender(novels,rels,num_characters,verb_stop,gender):\n",
    "    def of_interest(ent,rels,main_characters,gender):\n",
    "        if gender_guess(ent.text.strip().lower(),gender_map)==gender:\n",
    "            return (ent.text.strip().lower() in main_characters \n",
    "                    and ent.label_ == 'PERSON' \n",
    "                    and ent.root.head.pos_ == 'VERB'\n",
    "                    and ent.root.dep_ in rels)  \n",
    "\n",
    "    contexts = defaultdict(Counter)    \n",
    "    for parsed_novel in novels:\n",
    "        main_characters = get_main_characters(parsed_novel,num_characters)\n",
    "        stop_verbs=get_pos_in(parsed_novel,'VERB',verb_stop)\n",
    "        for ent in parsed_novel.ents:\n",
    "            if of_interest(ent,rels,main_characters,gender):\n",
    "                if ent.root.head.lemma_ not in stop_verbs:\n",
    "                    contexts[ent.text.strip().lower()][ent.root.head.lemma_] += 1\n",
    "    return contexts\n",
    "novels = {parsed_novel1,parsed_novel2}\n",
    "number_of_characters_per_text = 8\n",
    "target_rels = {'nsubj','dobj'}\n",
    "verb_stop=1000\n",
    "target_contexts = get_interesting_contexts_gender(novels,target_rels,number_of_characters_per_text,verb_stop,'male')\n",
    "display(pd.DataFrame.from_dict(target_contexts).applymap(lambda x: '' if math.isnan(x) else x))\n",
    "# C=(Counter(get_entities_in(parsed_novel,\"VERB\")).most_common())\n",
    "# get_pos_in(parsed_novel,'VERB',60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch feature sets of the 2 novels parsed of all the female characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amy</th>\n",
       "      <th>eloise</th>\n",
       "      <th>lady hammergallow</th>\n",
       "      <th>mandy ann</th>\n",
       "      <th>mrs jehoram</th>\n",
       "      <th>mrs mendham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>add</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrange</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assent</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boast</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>borrow</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chat</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chime</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>choke</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continue</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decide</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decline</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demur</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>design</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disappear</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drag</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>draw</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>droop</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drop</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exchange</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exclaim</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exercise</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forbear</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glance</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hesitate</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hold</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hop</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insist</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insult</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intrust</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistake</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>niggers</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nod</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parry</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persist</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>piece</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recover</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reflect</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rejoin</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relapse</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rub</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sink</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slip</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spring</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stoop</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suggest</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throw</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tie</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>welcome</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whisper</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>win</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrap</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          amy eloise lady hammergallow mandy ann mrs jehoram mrs mendham\n",
       "'                                              1                        \n",
       "add                                                                    1\n",
       "arrange            1                                                    \n",
       "assent      1                                                           \n",
       "boast                                          1                        \n",
       "borrow                                         1                        \n",
       "chat               1                                                    \n",
       "chime                                          1                        \n",
       "choke                                          1                        \n",
       "continue           1                           1                        \n",
       "decide      1                                                           \n",
       "decline            2                                                    \n",
       "demur              1                                                    \n",
       "design             1                                                    \n",
       "disappear                                      1                        \n",
       "drag                                           1                        \n",
       "draw        1      3                                                    \n",
       "droop       1                                                           \n",
       "drop               1                                                    \n",
       "exchange                                                   1            \n",
       "exclaim     1      3                 1         1                        \n",
       "exercise                             1                                  \n",
       "forbear            1                                                    \n",
       "glance             1                                                    \n",
       "hesitate                                       1                        \n",
       "hold                                 1                                  \n",
       "hop                1                                                    \n",
       "insist             2                                                    \n",
       "insult                                         1                        \n",
       "intrust                                        1                        \n",
       "lead        1                                                           \n",
       "mistake            1                                                    \n",
       "niggers                                        1                        \n",
       "nod                1                           1                        \n",
       "parry              1                                                    \n",
       "persist            1                                                    \n",
       "piece                                          1                        \n",
       "place                                          1                        \n",
       "recover                                                    1            \n",
       "reflect                                                                1\n",
       "rejoin      1      2                           1                        \n",
       "relapse     1                                                           \n",
       "rub                1                                                    \n",
       "rush                                           2                        \n",
       "sink               1                                                    \n",
       "slip                                           1                        \n",
       "spring             2                                                    \n",
       "stoop       1                                                           \n",
       "suggest            1                           1                        \n",
       "throw                                1                                  \n",
       "tie                1                                                    \n",
       "welcome                              1                                  \n",
       "whisper                                                    1            \n",
       "win                1                                                    \n",
       "wrap               1                                                    "
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_interesting_contexts_gender(novels,rels,num_characters,verb_stop,gender):\n",
    "    def of_interest(ent,rels,main_characters,gender):\n",
    "        if gender_guess(ent.text.strip().lower(),gender_map)==gender:\n",
    "            return (ent.text.strip().lower() in main_characters \n",
    "                    and ent.label_ == 'PERSON' \n",
    "                    and ent.root.head.pos_ == 'VERB'\n",
    "                    and ent.root.dep_ in rels)  \n",
    "\n",
    "    contexts = defaultdict(Counter)    \n",
    "    for parsed_novel in novels:\n",
    "        main_characters = get_main_characters(parsed_novel,num_characters)\n",
    "        stop_verbs=get_pos_in(parsed_novel,'VERB',verb_stop)\n",
    "        for ent in parsed_novel.ents:\n",
    "            if of_interest(ent,rels,main_characters,gender):\n",
    "                if ent.root.head.lemma_ not in stop_verbs:\n",
    "                    contexts[ent.text.strip().lower()][ent.root.head.lemma_] += 1\n",
    "    return contexts\n",
    "novels = { parsed_novel1,parsed_novel2}\n",
    "number_of_characters_per_text = 7\n",
    "target_rels = {'nsubj','dobj'}\n",
    "verb_stop=1000\n",
    "target_contexts = get_interesting_contexts_gender(novels,target_rels,number_of_characters_per_text,verb_stop,'female')\n",
    "display(pd.DataFrame.from_dict(target_contexts).applymap(lambda x: '' if math.isnan(x) else x))\n",
    "# C=(Counter(get_entities_in(parsed_novel,\"VERB\")).most_common())\n",
    "# get_pos_in(parsed_novel,'VERB',60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them. The cosine of 0Â° is 1, and it is less than 1 for any other angle. It is thus a judgment of orientation and not magnitude: two vectors with the same orientation have a cosine similarity of 1, two vectors at 90Â° have a similarity of 0, and two vectors diametrically opposed have a similarity of -1, independent of their magnitude. Cosine similarity is particularly used in positive space, where the outcome is neatly bounded in [0,1]. The name derives from the term \"direction cosine\": in this case, note that unit vectors are maximally \"similar\" if they're parallel and maximally \"dissimilar\" if they're orthogonal (perpendicular). This is analogous to the cosine, which is unity (maximum value) when the segments subtend a zero angle and zero (uncorrelated) when the segments are perpendicular.\n",
    "\n",
    "In practice, cosine similarity tends to be useful when trying to determine how similar two texts/documents are. Iâve seen it used for sentiment analysis, translation, and some rather brilliant work at Georgia Tech for detecting plagiarism. Cosine similarity works in these usecases because we ignore magnitude and focus solely on orientation. In NLP, this might help us still detect that a much longer document has the same âthemeâ as a much shorter document since we donât worry about the magnitude or the âlengthâ of the documents themselves.\n",
    "\n",
    "Intuitively, letâs say we have 2 vectors, each representing a sentence. If the vectors are close to parallel, maybe we assume that both sentences are âsimilarâ in theme. Whereas if the vectors are orthogonal, then we assume the sentences are independent or NOT âsimilarâ. Depending on your usecase, maybe you want to find very similar documents or very different documents, so you compute the cosine similarity.\n",
    "\n",
    "The business use case for cosine similarity involves comparing customer profiles, product profiles or text documents. The algorithmic question is whether two customer profiles are similar or not. Cosine similarity is perhaps the simplest way to determine this.\n",
    "\n",
    "If one can compare whether any two objects are similar, one can use the similarity as a building block to achieve more complex tasks, such as:\n",
    "\n",
    "- search: find the most similar document to a given one\n",
    "- classification: is some customer likely to buy that product\n",
    "- clustering: are there natural groups of similar documents\n",
    "- product recommendations: which products are similar to the customerâs past purchases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term \"cosine similarity\" is sometimes used to refer to a different definition of similarity provided below. However the most common use of \"cosine similarity\" is as defined above and the similarity and distance metrics defined below are referred to as \"angular similarity\" and \"angular distance\" respectively. The normalized angle between the vectors is a formal distance metric and can be calculated from the similarity score defined above. This angular distance metric can then be used to compute a similarity function bounded between 0 and 1, inclusive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting similarity ranges from â1 meaning exactly opposite, to 1 meaning exactly the same, with 0 indicating orthogonality (decorrelation), and in-between values indicating intermediate similarity or dissimilarity.\n",
    "\n",
    "For text matching, the attribute vectors A and B are usually the term frequency vectors of the documents. The cosine similarity can be seen as a method of normalizing document length during comparison.\n",
    "\n",
    "In the case of information retrieval, the cosine similarity of two documents will range from 0 to 1, since the term frequencies (tf-idf weights) cannot be negative. The angle between two term frequency vectors cannot be greater than 90Â°.\n",
    "\n",
    "If the attribute vectors are normalized by subtracting the vector means, the measure is called centered cosine similarity and is equivalent to the Pearson correlation coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of measuring cosine similarity\n",
    "\n",
    "Here are two very short texts to compare:\n",
    "\n",
    "Julie loves me more than Linda loves me\n",
    "\n",
    "Jane likes me more than Julie loves me\n",
    "\n",
    "We want to know how similar these texts are, purely in terms of word counts (and ignoring word order). We begin by making a list of the words from both texts:\n",
    "\n",
    "me Julie loves Linda than more likes Jane\n",
    "\n",
    "Now we count the number of times each of these words appears in each text:\n",
    "\n",
    "   me   2   2\n",
    " Jane   0   1\n",
    "Julie   1   1\n",
    "Linda   1   0\n",
    "likes   0   1\n",
    "loves   2   1\n",
    " more   1   1\n",
    " than   1   1\n",
    "We are not interested in the words themselves though. We are interested only in those two vertical vectors of counts. For instance, there are two instances of 'me' in each text. We are going to decide how close these two texts are to each other by calculating one function of those two vectors, namely the cosine of the angle between them.\n",
    "\n",
    "The two vectors are, again:\n",
    "\n",
    "a: [2, 1, 0, 2, 0, 1, 1, 1]\n",
    "\n",
    "b: [2, 1, 1, 1, 1, 0, 1, 1]\n",
    "The cosine of the angle between them is about 0.822.\n",
    "\n",
    "These vectors are 8-dimensional. A virtue of using cosine similarity is clearly that it converts a question that is beyond human ability to visualise to one that can be. In this case you can think of this as the angle of about 35 degrees which is some 'distance' from zero or perfect agreement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring cosine similarity in two sets of genders to encapsulate differences in feature portrayal\n",
    "\n",
    "The interesting contexts function is modeified to return the counter object of verbs associated with their frequencies.\n",
    "The function in Topic 8 is used to calculate the cosine similarity between the 2 counter objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32136453035056578"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_interesting_contexts_gender(novels,rels,num_characters,verb_stop,gender):\n",
    "    def of_interest(ent,rels,main_characters,gender):\n",
    "        if gender_guess(ent.text.strip().lower(),gender_map)==gender:\n",
    "            return (ent.text.strip().lower() in main_characters \n",
    "                    and ent.label_ == 'PERSON' \n",
    "                    and ent.root.head.pos_ == 'VERB'\n",
    "                    and ent.root.dep_ in rels)  \n",
    "\n",
    "    contexts = defaultdict(Counter)    \n",
    "    for parsed_novel in novels:\n",
    "        main_characters = get_main_characters(parsed_novel,num_characters)\n",
    "        stop_verbs=get_pos_in(parsed_novel,'VERB',verb_stop)\n",
    "        for ent in parsed_novel.ents:\n",
    "            if of_interest(ent,rels,main_characters,gender):\n",
    "                if ent.root.head.lemma_ not in stop_verbs:\n",
    "                    contexts[ent.text.strip().lower()][ent.root.head.lemma_] += 1\n",
    "    df=(pd.DataFrame.from_dict(contexts).applymap(lambda x: 0 if math.isnan(x) else x))\n",
    "    return Counter(dict(df.sum(axis=1)))\n",
    "\n",
    "A = get_interesting_contexts_gender(novels,target_rels,number_of_characters_per_text,verb_stop,'male')\n",
    "B = get_interesting_contexts_gender(novels,target_rels,number_of_characters_per_text,verb_stop,'female')\n",
    "\n",
    "def counters_to_feature_lists(counter1,counter2):\n",
    "    combined = counter1 + counter2 \n",
    "    list1 = [counter1[key] for key in combined]\n",
    "    list2 = [counter2[key] for key in combined]\n",
    "    return list1,list2\n",
    "Counter(A)\n",
    "L1,L2 = counters_to_feature_lists(A,B)\n",
    "# print(L1)\n",
    "# print(L2)\n",
    "cosine_similarity([L1], [L2])[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The cosine similarity comes out to be 0.32 which is less than 1, signifying a significant difference in the feature sets of the male and female class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.805911695214\n"
     ]
    }
   ],
   "source": [
    "def get_interesting_contexts(novels,rels,num_characters,verb_stop):\n",
    "    def of_interest(ent,rels,main_characters):\n",
    "        return (ent.text.strip().lower() in main_characters \n",
    "                and ent.label_ == 'PERSON' \n",
    "                and ent.root.head.pos_ == 'VERB'\n",
    "                and ent.root.dep_ in rels)  \n",
    "\n",
    "    contexts = defaultdict(Counter)    \n",
    "    for parsed_novel in novels:\n",
    "        main_characters = get_main_characters(parsed_novel,num_characters)\n",
    "        stop_verbs=get_pos_in(parsed_novel,'VERB',verb_stop)\n",
    "        for ent in parsed_novel.ents:\n",
    "            if of_interest(ent,rels,main_characters):\n",
    "                if ent.root.head.lemma_ not in stop_verbs:\n",
    "                    contexts[ent.text.strip().lower()][ent.root.head.lemma_] += 1\n",
    "    df=(pd.DataFrame.from_dict(contexts).applymap(lambda x: 0 if math.isnan(x) else x))\n",
    "    A=df.iloc[:,:5]\n",
    "    A_=Counter(dict(A.sum(axis=1)))\n",
    "#     B=df.iloc[:,5:]\n",
    "#     A_=Counter(dict(B.sum(axis=1)))\n",
    "    return A_\n",
    "    \n",
    "novels = {parsed_novel1,parsed_novel2}\n",
    "number_of_characters_per_text=8\n",
    "target_rels = {'nsubj','dobj'}  \n",
    "A_count = get_interesting_contexts(novels,target_rels,number_of_characters_per_text,100)\n",
    "\n",
    "\n",
    "def get_interesting_contexts(novels,rels,num_characters,verb_stop):\n",
    "    def of_interest(ent,rels,main_characters):\n",
    "        return (ent.text.strip().lower() in main_characters \n",
    "                and ent.label_ == 'PERSON' \n",
    "                and ent.root.head.pos_ == 'VERB'\n",
    "                and ent.root.dep_ in rels)  \n",
    "\n",
    "    contexts = defaultdict(Counter)    \n",
    "    for parsed_novel in novels:\n",
    "        main_characters = get_main_characters(parsed_novel,num_characters)\n",
    "        stop_verbs=get_pos_in(parsed_novel,'VERB',verb_stop)\n",
    "        for ent in parsed_novel.ents:\n",
    "            if of_interest(ent,rels,main_characters):\n",
    "                if ent.root.head.lemma_ not in stop_verbs:\n",
    "                    contexts[ent.text.strip().lower()][ent.root.head.lemma_] += 1\n",
    "    df=(pd.DataFrame.from_dict(contexts).applymap(lambda x: 0 if math.isnan(x) else x))\n",
    "    B=df.iloc[:,5:]\n",
    "    B_=Counter(dict(B.sum(axis=1)))\n",
    "#     B=df.iloc[:,5:]\n",
    "#     A_=Counter(dict(B.sum(axis=1)))\n",
    "    return B_\n",
    "\n",
    "B_count = get_interesting_contexts(novels,target_rels,number_of_characters_per_text,100)\n",
    "\n",
    "\n",
    "def counters_to_feature_lists(counter1,counter2):\n",
    "    combined = counter1 + counter2 \n",
    "    list1 = [counter1[key] for key in combined]\n",
    "    list2 = [counter2[key] for key in combined]\n",
    "    return list1,list2\n",
    "\n",
    "L1,L2 = counters_to_feature_lists(A_count,B_count)\n",
    "# print(L1)\n",
    "# print(L2)\n",
    "a=cosine_similarity([L1], [L2])[0,0]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case where 8 characters are selected from the 2 novels, and split is made on basis of first 4 and last 4 entries, there is a mix of male and female entities in both the sample sets. The cosine similarity turns out to be 0.8, which is approximately close to 1. The verb stopping criteria was set to filter out top 200 common verbs.\n",
    "\n",
    "In the dataset we have used, the genders are balanced approximately, with 5 male and 6 female characters that are used to assess gender wise differences in the characters obtained, so it can be said the low value for cosine similarity obtained can't be attributed to gender imbalance.\n",
    "\n",
    "The effects of a gender imbalance would definitely bias the cosine similarity values as the corpus for majority class has more root lemmas in total, and the frequency of each term is also enhanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}